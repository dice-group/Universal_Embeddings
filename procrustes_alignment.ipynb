{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "handled-engineer",
   "metadata": {},
   "source": [
    "## OpenEA datasets. We consider RotatE and TransE embedding approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "subjective-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from scipy.spatial import procrustes\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import time, gc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "gc.enable()\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "capital-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_and_target_matrices(alignment_dict, entity2vec1, entity2vec2, given_test_set=None, emb_dim=50, test_size=0.1, rescale=True, shift=True):\n",
    "    \"\"\"This function takes the dictionary of aligned entities between two KGs and their corresponding embeddings (as entity to vector dictionaries)\n",
    "    and returns S, T, S_test, T_test, and R defined as follows:\n",
    "    \n",
    "    -- S: Normalized and scaled large subset of the source embeddings, i.e. the matrix of aligned entity embeddings in the first knowledge graph\n",
    "    \n",
    "    -- T: Normalized and scaled large subset of the matrix of aligned entity embeddings in the second knowledge graph\n",
    "    \n",
    "    -- S_test and T_test are portions of the full matrices sampled for evaluation if test_size > 0. If 'given_test_set' is given, it takes priority, i.e., no sampling is performed\n",
    "    \n",
    "    -- R: The rotation matrix that most closely maps S to T, i.e. ||A@S-T|| is minimized\n",
    "    \n",
    "    The mean and standard deviation of S, T are also returned\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    if test_size > 0 or given_test_set:\n",
    "        if given_test_set is None:\n",
    "            train_ents, test_ents = train_test_split(list(alignment_dict.keys()), test_size=test_size, random_state=42)\n",
    "        else:\n",
    "            test_ents = given_test_set\n",
    "            train_ents = list(set(alignment_dict.keys())-set(test_ents))\n",
    "    else:\n",
    "        train_ents = alignment_dict.keys()\n",
    "    \n",
    "    S = entity2vec1.loc[train_ents].values\n",
    "    T = entity2vec2.loc[list(map(alignment_dict.get, train_ents))].values\n",
    "    \n",
    "    S_test = entity2vec1.loc[test_ents].values\n",
    "    T_test = entity2vec2.loc[list(map(alignment_dict.get, test_ents))].values\n",
    "        \n",
    "    print('\\nNow computing R...')\n",
    "    # Center and scale data\n",
    "    mean_S = S.mean(axis=0)\n",
    "    mean_T = T.mean(axis=0)\n",
    "    scale_S = np.sqrt(((S-mean_S)**2).sum()/S.shape[0]) # scale, see https://en.wikipedia.org/wiki/Procrustes_analysis\n",
    "    scale_T = np.sqrt(((T-mean_T)**2).sum()/T.shape[0])\n",
    "    print('Scale S: ', scale_S)\n",
    "    \n",
    "    if shift and rescale:\n",
    "        R, loss = orthogonal_procrustes((S-mean_S)/scale_S, (T-mean_T)/scale_T, check_finite=False)\n",
    "        print('\\nCompleted after '+str(time.time()-t0)+' seconds')\n",
    "    elif shift:\n",
    "        R, loss = orthogonal_procrustes((S-mean_S), (T-mean_T), check_finite=False)\n",
    "        print('\\nCompleted after '+str(time.time()-t0)+' seconds')\n",
    "    elif rescale:\n",
    "        R, loss = orthogonal_procrustes(S/scale_S, T/scale_T, check_finite=False)\n",
    "        print('\\nCompleted after '+str(time.time()-t0)+' seconds')\n",
    "    else:\n",
    "        R, loss = orthogonal_procrustes(S, T, check_finite=False)\n",
    "        print('\\nCompleted after '+str(time.time()-t0)+' seconds')\n",
    "        \n",
    "    print('Alignment loss: ', loss)\n",
    "    if test_size > 0 or given_test_set:\n",
    "        if shift and rescale:\n",
    "            return scale_S, scale_T, mean_S, mean_T, (S-mean_S)/scale_S, (T-mean_T)/scale_T, (S_test-mean_S)/scale_S, (T_test-mean_T)/scale_T, R\n",
    "        elif shift:\n",
    "            return scale_S, scale_T, mean_S, mean_T, S-mean_S, T-mean_T, S_test-mean_S, T_test-mean_T, R\n",
    "        elif rescale:\n",
    "            return scale_S, scale_T, mean_S, mean_T, S/scale_S, T/scale_T, S_test/scale_S, T_test/scale_T, R\n",
    "        else:\n",
    "            return scale_S, scale_T, mean_S, mean_T, S, T, S_test, T_test, R\n",
    "    else:\n",
    "        if shift and rescale:\n",
    "            return scale_S, scale_T, mean_S, mean_T, (S-mean_S)/scale_S, (T-mean_T)/scale_T, R\n",
    "        elif shift:\n",
    "            return scale_S, scale_T, mean_S, mean_T, S-mean_S, T-mean_T, R\n",
    "        elif rescale:\n",
    "            return scale_S, scale_T, mean_S, mean_T, S/scale_S, T/scale_T, R\n",
    "        else:\n",
    "            return scale_S, scale_T, mean_S, mean_T, S, T, R\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "logical-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_aligned_entity_embedding_matrices(alignment_dict, entity2vec1, entity2vec2, scale_S, scale_T, mean_S, mean_T, emb_dim=200):\n",
    "    \"\"\"\n",
    "    Inputs the dictionary of aligned entities between two KGs and their corresponding embeddings, and returns the normalized embedding matrices of \n",
    "    \n",
    "    non-aligned entities\n",
    "    \"\"\"\n",
    "    A_neg_S = np.empty((len(entity2vec1)-len(alignment_dict), emb_dim))\n",
    "    keys = sorted(set(entity2vec1.index)-set(alignment_dict.keys()))\n",
    "    for i, key in tqdm(enumerate(keys), total=A_neg_S.shape[0], desc='Computing A_neg_S...'):\n",
    "        A_neg_S[i] = entity2vec1.loc[key].values\n",
    "    \n",
    "    B_neg_T = np.empty((len(entity2vec2)-len(alignment_dict), emb_dim))\n",
    "    keys = sorted(set(entity2vec2.index)-set(alignment_dict.values()))\n",
    "    for i, key in tqdm(enumerate(keys), total=B_neg_T.shape[0], desc='Computing B_neg_T...'):\n",
    "        B_neg_T[i] = entity2vec2.loc[key].values\n",
    "        \n",
    "    return (A_neg_S-mean_S)/scale_S, (B_neg_T-mean_T)/scale_T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "individual-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_alignment_knn(S_test, T_test, R, assume_known=False, hit_values = [1, 3, 10]):\n",
    "    \"\"\"The function takes the evaluation sets, i.e. correct alignments that were left out, and returns the hits@ and MRR results w.r.t. correct alignments\n",
    "    \n",
    "    --assume_known. A boolean variable. When set to True, the alignment results are computed using the fact that the test links are known\n",
    "    \n",
    "    \"\"\"\n",
    "    print('#'*50)\n",
    "    print('Evaluation started...')\n",
    "    print('#'*50)\n",
    "    model = NearestNeighbors(n_neighbors=S_test.shape[0], n_jobs=-1)\n",
    "    print('Fitting 1...')\n",
    "    model.fit(T_test)\n",
    "    print('Predicting 1...')\n",
    "    if assume_known:\n",
    "        preds = model.kneighbors((S_test@R+T_test)/2, n_neighbors=S_test.shape[0], return_distance=False)\n",
    "    else:\n",
    "        preds = model.kneighbors(S_test, n_neighbors=S_test.shape[0], return_distance=False)\n",
    "    Hits1 = np.zeros(len(hit_values))\n",
    "    MRR1 = 0.0\n",
    "    for i in tqdm(range(S_test.shape[0]), total=S_test.shape[0]):\n",
    "        pred_idx = (preds[i]==i).nonzero()[0][0]\n",
    "        MRR1 += (1./(pred_idx+1))\n",
    "        for j in range(len(Hits1)):\n",
    "            if pred_idx < hit_values[j]:\n",
    "                Hits1[j] = Hits1[j] + 1.0\n",
    "    Hits1 = Hits1/S_test.shape[0]\n",
    "    MRR1 = MRR1/S_test.shape[0]\n",
    "    \n",
    "    model = NearestNeighbors(n_neighbors=S_test.shape[0], n_jobs=-1)\n",
    "    print('\\nFitting 2...')\n",
    "    if assume_known:\n",
    "        model.fit((S_test@R+T_test)/2)\n",
    "    else:\n",
    "        model.fit(S_test)\n",
    "    print('Predicting 2...')\n",
    "    preds = model.kneighbors(T_test, n_neighbors=S_test.shape[0], return_distance=False)\n",
    "    Hits2 = np.zeros(len(hit_values))\n",
    "    MRR2 = 0.0\n",
    "    for i in tqdm(range(S_test.shape[0]), total=S_test.shape[0]):\n",
    "        pred_idx = (preds[i]==i).nonzero()[0][0] # if i in preds[i] else S_test.shape[0]\n",
    "        MRR2 += (1./(pred_idx+1))\n",
    "        for j in range(len(Hits2)):\n",
    "            if pred_idx < hit_values[j]:\n",
    "                Hits2[j] = Hits2[j] + 1.0\n",
    "    Hits2 = Hits2/S_test.shape[0]\n",
    "    MRR2 = MRR2/S_test.shape[0]\n",
    "    \n",
    "    Hits = (Hits1+Hits2)/2\n",
    "    MRR = (MRR1+MRR2)/2\n",
    "    print()\n",
    "    print(', '.join([f'Hits@{hit_values[it]}: {Hits[it]}' for it in range(len(Hits))]+[f'MRR: {MRR}']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-connecticut",
   "metadata": {},
   "source": [
    "## Define functions to load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ruled-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_alignment_dict(kg_name):\n",
    "    with open(f'OpenEA_dataset_v2.0/{kg_name}/ent_links') as file:\n",
    "        kg1_to_kg2 = file.read().strip().split('\\n')\n",
    "    kg1_to_kg2 = dict([line.split('\\t') for line in kg1_to_kg2])\n",
    "    return kg1_to_kg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "formal-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_entities(kg_name, fold):\n",
    "    with open(f'OpenEA_dataset_v2.0/{kg_name}/721_5fold/{fold}/test_links') as file:\n",
    "        test_links = file.read().strip().split('\\n')\n",
    "    test_links = [line.split('\\t')[0] for line in test_links]\n",
    "    return test_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sunset-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(kg_name, emb_model=\"TransE\"):\n",
    "    if emb_model == \"TransE\":\n",
    "        model1 = torch.load(f'OpenEA_dataset_v2.0/{kg_name}/KG1_TransE/trained_model.pkl', map_location='cpu').eval()\n",
    "        model2 = torch.load(f'OpenEA_dataset_v2.0/{kg_name}/KG2_TransE/trained_model.pkl', map_location='cpu').eval()\n",
    "        with open(f'OpenEA_dataset_v2.0/{kg_name}/KG1_TransE/entity_to_ids.json') as file:\n",
    "            ent_ids1 = json.load(file)\n",
    "        with open(f'OpenEA_dataset_v2.0/{kg_name}/KG2_TransE/entity_to_ids.json') as file:\n",
    "            ent_ids2 = json.load(file)\n",
    "        emb1 = pd.DataFrame(model1.entity_representations[0](torch.tensor(list(ent_ids1.values())).long()).tolist(), index=list(ent_ids1.keys()))\n",
    "        emb2 = pd.DataFrame(model2.entity_representations[0](torch.tensor(list(ent_ids2.values())).long()).tolist(), index=list(ent_ids2.keys()))\n",
    "    else:\n",
    "        model1 = torch.load(f'OpenEA_dataset_v2.0/{kg_name}/KG1_RotatE/trained_model.pkl', map_location='cpu')\n",
    "        model2 = torch.load(f'OpenEA_dataset_v2.0/{kg_name}/KG2_RotatE/trained_model.pkl', map_location='cpu')\n",
    "        with open(f'OpenEA_dataset_v2.0/{kg_name}/KG1_RotatE/entity_to_ids.json') as file:\n",
    "            ent_ids1 = json.load(file)\n",
    "        with open(f'OpenEA_dataset_v2.0/{kg_name}/KG2_RotatE/entity_to_ids.json') as file:\n",
    "            ent_ids2 = json.load(file)\n",
    "            \n",
    "        emb1_real = model1.entity_representations[0](torch.tensor(list(ent_ids1.values())).long()).real\n",
    "        emb1_img = model1.entity_representations[0](torch.tensor(list(ent_ids1.values())).long()).imag\n",
    "        emb1 = torch.cat([emb1_real, emb1_img], axis=-1)\n",
    "        \n",
    "        emb2_real = model2.entity_representations[0](torch.tensor(list(ent_ids2.values())).long()).real\n",
    "        emb2_img = model2.entity_representations[0](torch.tensor(list(ent_ids2.values())).long()).imag\n",
    "        emb2 = torch.cat([emb2_real, emb2_img], axis=-1)\n",
    "        \n",
    "        emb1 = pd.DataFrame(emb1.tolist(), index=list(ent_ids1.keys()))\n",
    "        emb2 = pd.DataFrame(emb2.tolist(), index=list(ent_ids2.keys()))\n",
    "    return emb1, emb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "minor-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment = build_alignment_dict(\"EN_FR_15K_V1\")\n",
    "test_entities = get_test_entities(\"EN_FR_15K_V1\", 1)\n",
    "emb1, emb2 = get_embeddings(\"EN_FR_15K_V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "distant-valuation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.010982</td>\n",
       "      <td>-0.029167</td>\n",
       "      <td>0.050871</td>\n",
       "      <td>-0.086290</td>\n",
       "      <td>-0.006217</td>\n",
       "      <td>-0.006347</td>\n",
       "      <td>0.032373</td>\n",
       "      <td>-0.008046</td>\n",
       "      <td>-0.009607</td>\n",
       "      <td>-0.089063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087316</td>\n",
       "      <td>-0.031542</td>\n",
       "      <td>0.031592</td>\n",
       "      <td>0.072944</td>\n",
       "      <td>0.042461</td>\n",
       "      <td>-0.089679</td>\n",
       "      <td>-0.056860</td>\n",
       "      <td>0.020393</td>\n",
       "      <td>0.085451</td>\n",
       "      <td>0.038364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Live)</th>\n",
       "      <td>0.001938</td>\n",
       "      <td>-0.010675</td>\n",
       "      <td>0.056120</td>\n",
       "      <td>-0.409321</td>\n",
       "      <td>0.192670</td>\n",
       "      <td>-0.287279</td>\n",
       "      <td>0.033135</td>\n",
       "      <td>-0.010020</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>-0.279517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096294</td>\n",
       "      <td>-0.027402</td>\n",
       "      <td>0.356884</td>\n",
       "      <td>0.091503</td>\n",
       "      <td>-0.018329</td>\n",
       "      <td>-0.076187</td>\n",
       "      <td>-0.052801</td>\n",
       "      <td>0.026452</td>\n",
       "      <td>0.089548</td>\n",
       "      <td>0.046538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6   \\\n",
       "         0.010982 -0.029167  0.050871 -0.086290 -0.006217 -0.006347  0.032373   \n",
       " (Live)  0.001938 -0.010675  0.056120 -0.409321  0.192670 -0.287279  0.033135   \n",
       "\n",
       "               7         8         9   ...        40        41        42  \\\n",
       "        -0.008046 -0.009607 -0.089063  ... -0.087316 -0.031542  0.031592   \n",
       " (Live) -0.010020  0.000702 -0.279517  ... -0.096294 -0.027402  0.356884   \n",
       "\n",
       "               43        44        45        46        47        48        49  \n",
       "         0.072944  0.042461 -0.089679 -0.056860  0.020393  0.085451  0.038364  \n",
       " (Live)  0.091503 -0.018329 -0.076187 -0.052801  0.026452  0.089548  0.046538  \n",
       "\n",
       "[2 rows x 50 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "enormous-yesterday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th># (US Mainstream Rock)</th>\n",
       "      <td>0.177219</td>\n",
       "      <td>-0.192868</td>\n",
       "      <td>-0.252988</td>\n",
       "      <td>-0.357779</td>\n",
       "      <td>-0.307341</td>\n",
       "      <td>0.047987</td>\n",
       "      <td>-0.455507</td>\n",
       "      <td>0.02786</td>\n",
       "      <td>0.191631</td>\n",
       "      <td>-0.109535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160491</td>\n",
       "      <td>0.168667</td>\n",
       "      <td>0.087189</td>\n",
       "      <td>0.068281</td>\n",
       "      <td>-0.118001</td>\n",
       "      <td>-0.071306</td>\n",
       "      <td>-0.064774</td>\n",
       "      <td>-0.055225</td>\n",
       "      <td>-0.010741</td>\n",
       "      <td>-0.006808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># (US Modern Rock)</th>\n",
       "      <td>0.160445</td>\n",
       "      <td>-0.179548</td>\n",
       "      <td>-0.263566</td>\n",
       "      <td>-0.345250</td>\n",
       "      <td>-0.318889</td>\n",
       "      <td>0.047559</td>\n",
       "      <td>-0.463212</td>\n",
       "      <td>0.02890</td>\n",
       "      <td>0.190284</td>\n",
       "      <td>-0.102479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168589</td>\n",
       "      <td>0.156612</td>\n",
       "      <td>0.087659</td>\n",
       "      <td>0.054049</td>\n",
       "      <td>-0.118439</td>\n",
       "      <td>-0.069497</td>\n",
       "      <td>-0.081031</td>\n",
       "      <td>-0.067076</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>-0.006222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0         1         2         3         4   \\\n",
       "# (US Mainstream Rock)  0.177219 -0.192868 -0.252988 -0.357779 -0.307341   \n",
       "# (US Modern Rock)      0.160445 -0.179548 -0.263566 -0.345250 -0.318889   \n",
       "\n",
       "                              5         6        7         8         9   ...  \\\n",
       "# (US Mainstream Rock)  0.047987 -0.455507  0.02786  0.191631 -0.109535  ...   \n",
       "# (US Modern Rock)      0.047559 -0.463212  0.02890  0.190284 -0.102479  ...   \n",
       "\n",
       "                              40        41        42        43        44  \\\n",
       "# (US Mainstream Rock) -0.160491  0.168667  0.087189  0.068281 -0.118001   \n",
       "# (US Modern Rock)     -0.168589  0.156612  0.087659  0.054049 -0.118439   \n",
       "\n",
       "                              45        46        47        48        49  \n",
       "# (US Mainstream Rock) -0.071306 -0.064774 -0.055225 -0.010741 -0.006808  \n",
       "# (US Modern Rock)     -0.069497 -0.081031 -0.067076  0.003138 -0.006222  \n",
       "\n",
       "[2 rows x 50 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adjacent-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  0.8341125927861606\n",
      "\n",
      "Completed after 0.09527587890625 seconds\n",
      "Alignment loss:  3285.2662817510895\n"
     ]
    }
   ],
   "source": [
    "scale_S, scale_T, mean_S, mean_T, S, T, S_test, T_test, R = get_source_and_target_matrices(alignment,\\\n",
    "                                                emb1, emb2, given_test_set=None, emb_dim=50, rescale=False, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "smart-fiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 50)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "chinese-brisbane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting 1...\n",
      "Predicting 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:00<00:00, 110461.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2...\n",
      "Predicting 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1500/1500 [00:00<00:00, 108969.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hits@5: 0.0033333333333333335, Hits@10: 0.008, Hits@50: 0.039, MRR: 0.005619881159665557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_alignment_knn(S_test, T_test, R, assume_known=False, hit_values=[5, 10, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-dominican",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cultural-politics",
   "metadata": {},
   "source": [
    "## With RotatE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "primary-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1, emb2 = get_embeddings(\"EN_FR_15K_V1\", \"RotatE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "initial-jaguar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.001671</td>\n",
       "      <td>-0.001787</td>\n",
       "      <td>-0.002695</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>-0.003109</td>\n",
       "      <td>-0.001952</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006454</td>\n",
       "      <td>-0.001332</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>-0.005879</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.003362</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.003020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Live)</th>\n",
       "      <td>-0.007722</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>-0.004285</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>-0.010752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>-0.011252</td>\n",
       "      <td>0.009744</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.003118</td>\n",
       "      <td>0.011277</td>\n",
       "      <td>-0.009715</td>\n",
       "      <td>-0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(UK)</th>\n",
       "      <td>0.003493</td>\n",
       "      <td>-0.000377</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>-0.001830</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005256</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.003244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6    \\\n",
       "        -0.001671 -0.001787 -0.002695 -0.000460 -0.000038  0.003914  0.001309   \n",
       " (Live) -0.007722  0.009663  0.003048  0.002181 -0.000333  0.004548  0.002331   \n",
       " (UK)    0.003493 -0.000377  0.001211  0.003132  0.001576  0.001537  0.002182   \n",
       "\n",
       "              7         8         9    ...       390       391       392  \\\n",
       "        -0.003109 -0.001952  0.000562  ... -0.006454 -0.001332  0.000671   \n",
       " (Live) -0.004285  0.001333 -0.010752  ...  0.005537  0.004850 -0.011252   \n",
       " (UK)   -0.001830  0.005519  0.006237  ... -0.005256  0.000204 -0.000745   \n",
       "\n",
       "              393       394       395       396       397       398       399  \n",
       "         0.008175 -0.005879  0.003883 -0.003430 -0.003362  0.002849  0.003020  \n",
       " (Live)  0.009744  0.000380 -0.003004 -0.003118  0.011277 -0.009715 -0.000115  \n",
       " (UK)    0.005057 -0.001026  0.005580  0.005439  0.000691  0.002482  0.003244  \n",
       "\n",
       "[3 rows x 400 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "damaged-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  1.3987306919266569\n",
      "\n",
      "Completed after 0.36179161071777344 seconds\n",
      "Alignment loss:  15137.798050691987\n"
     ]
    }
   ],
   "source": [
    "scale_S, scale_T, mean_S, mean_T, S, T, S_test, T_test, R = get_source_and_target_matrices(alignment,\\\n",
    "                                                emb1, emb2, given_test_set=None, emb_dim=400, rescale=False, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "resident-keeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting 1...\n",
      "Predicting 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:00<00:00, 100705.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2...\n",
      "Predicting 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:00<00:00, 111542.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hits@5: 0.003, Hits@10: 0.006333333333333333, Hits@50: 0.033, MRR: 0.005582873518672749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_alignment_knn(S_test, T_test, R, assume_known=False, hit_values=[5, 10, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-basketball",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "elder-hunter",
   "metadata": {},
   "source": [
    "## Another dataset: EN_FR_100K_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "handmade-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment = build_alignment_dict(\"EN_FR_100K_V1\")\n",
    "test_entities = get_test_entities(\"EN_FR_100K_V1\", 1)\n",
    "emb1, emb2 = get_embeddings(\"EN_FR_100K_V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "rapid-composer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  0.5238434249154881\n",
      "\n",
      "Completed after 0.6284322738647461 seconds\n",
      "Alignment loss:  17580.037182179432\n"
     ]
    }
   ],
   "source": [
    "scale_S, scale_T, mean_S, mean_T, S, T, S_test, T_test, R = get_source_and_target_matrices(alignment,\\\n",
    "                                                emb1, emb2, given_test_set=None, emb_dim=50, rescale=False, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "matched-officer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting 1...\n",
      "Predicting 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 45222.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2...\n",
      "Predicting 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 46706.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hits@5: 0.0007, Hits@10: 0.0010999999999999998, Hits@50: 0.0056, Hits@1000: 0.10805000000000001, MRR: 0.0010776550452930855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_alignment_knn(S_test, T_test, R, assume_known=False, hit_values=[5, 10, 50, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-fundamental",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-moral",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unikge",
   "language": "python",
   "name": "unikge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
