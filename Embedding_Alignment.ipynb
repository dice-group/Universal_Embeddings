{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baking-importance",
   "metadata": {},
   "source": [
    "# Dbpedia and Caligraph---Reading files and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "living-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "base_path = !pwd\n",
    "base_path = base_path[0]\n",
    "list_files = [base_path+\"/data/caligraph/\"+f for f in os.listdir(base_path+\"/data/caligraph/\") if os.path.isfile(base_path+\"/data/caligraph/\"+f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regulation-automation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-provenance.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-transitive-types.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-to-dbpedia-mappings.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-labels.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-ontology.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-relations.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-types.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-class-to-dbpedia.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-provenance.nt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "derived-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(list_files[2]) as file:\n",
    "    caligraph2dbpedia_mappings = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "affected-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(mapping):\n",
    "    x,_,y,_ = mapping.split()\n",
    "    return x.strip('<>'), y.strip('<>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "official-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "caligraph2dbpedia_mappings = dict(map(lambda x: get_map(x), caligraph2dbpedia_mappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sudden-newcastle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://caligraph.org/resource/Cameroon_sheep',\n",
       " 'http://dbpedia.org/resource/Cameroon_sheep')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(caligraph2dbpedia_mappings.items())[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fitting-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbpedia2caligraph_mappings = {value: key for key,value in caligraph2dbpedia_mappings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fourth-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "promising-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_caligraph = KeyedVectors.load(\"./Caligraph_Dbpedia/caligraph/caligraph-v211_500_4_sg_200_vectors.kv\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "crucial-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_dbpedia = KeyedVectors.load(\"./Caligraph_Dbpedia/dbpedia/dbpedia.kv\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-disney",
   "metadata": {},
   "source": [
    "### There are mismatches between entity IRIs in 'caligraph2dbpedia_mappings' and those in the computed embeddings, see below. We will write a function that fixes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "grand-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_namespace(iri, kg='dbpedia'):\n",
    "    if kg == 'dbpedia':\n",
    "        if 'owl#' in iri:\n",
    "            return iri\n",
    "        iri = iri.replace('dbr:', 'http://dbpedia.org/resource/')\n",
    "        return 'http://dbpedia.org/resource/' + iri.split('/')[-1]\n",
    "    elif kg == 'caligraph':\n",
    "        if 'owl#' in iri or 'ontology' in iri:\n",
    "            return iri\n",
    "        return 'http://caligraph.org/resource/' + iri.split('/')[-1]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "confused-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emb_keys_db = set(map(lambda t: repair_namespace(t), word_vectors_dbpedia.key_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "grateful-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emb_keys_cal = set(map(lambda t: repair_namespace(t, 'caligraph'), word_vectors_caligraph.key_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unlikely-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-durham",
   "metadata": {},
   "source": [
    "### Creating entity to vector maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bronze-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2vec_db = {}\n",
    "entity2vec_cal = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prospective-context",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15048578/15048578 [02:26<00:00, 102954.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for ent in tqdm(word_vectors_dbpedia.key_to_index):\n",
    "    try:\n",
    "        entity2vec_db[repair_namespace(ent)] = np.array(word_vectors_dbpedia.get_vector(ent))\n",
    "    except KeyError:\n",
    "        if repair_namespace(ent) in entity2vec_db:\n",
    "            entity2vec_db.pop(repair_namespace(ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "renewable-resident",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16429696/16429696 [02:50<00:00, 96382.36it/s] \n"
     ]
    }
   ],
   "source": [
    "for ent in tqdm(word_vectors_caligraph.key_to_index):\n",
    "    try:\n",
    "        entity2vec_cal[repair_namespace(ent, 'caligraph')] = np.array(word_vectors_caligraph.get_vector(ent), )\n",
    "    except KeyError:\n",
    "        if repair_namespace(ent) in entity2vec_cal:\n",
    "            entity2vec_cal.pop(repair_namespace(ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "contrary-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_vectors_dbpedia, word_vectors_caligraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "infinite-talent",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8320865/8320865 [00:25<00:00, 331921.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  3745232  aligned entities with available embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_aligned_entity_dict = dict()\n",
    "\n",
    "for key, value in tqdm(caligraph2dbpedia_mappings.items()):\n",
    "    if key in entity2vec_cal and value in entity2vec_db:\n",
    "        new_aligned_entity_dict.update({key: value})\n",
    "print('There are ', len(new_aligned_entity_dict), ' aligned entities with available embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Caligraph_Dbpedia/caligraph2dbpediaalignment.json', 'w') as file:\n",
    "#    json.dump(new_aligned_entity_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-exclusion",
   "metadata": {},
   "source": [
    "# Computing aligned KG embeddings using Orthogonal Procrustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "needed-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import procrustes\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import time, gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-bangkok",
   "metadata": {},
   "source": [
    "## Get the embedding matrices of aligned an non-aligned entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "processed-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_and_target_matrices(alignment_dict, entity2vec1, entity2vec2, emb_dim=200, test_size=0.1):\n",
    "    \"\"\"This function takes the dictionary of aligned entities between two KGs and their corresponding embeddings (as entity to vector dictionaries)\n",
    "    and returns S, T, S_eval, T_eval, and R defined as follows:\n",
    "    \n",
    "    -- S: Normalized large subset of the source embeddings, i.e. the matrix of aligned entity embeddings in the first knowledge graph\n",
    "    \n",
    "    -- T: Normalized large subset of the matrix of aligned entity embeddings in the second knowledge graph\n",
    "    \n",
    "    -- S_eval and T_eval are portions of S and T sampled for evaluation if test_size > 0\n",
    "    \n",
    "    -- R: The rotation matrix that most closely maps S to T, i.e. ||A@S-T|| is minimized\n",
    "    \"\"\"\n",
    "    if test_size > 0:\n",
    "        train_ents, eval_ents = train_test_split(list(alignment_dict.keys()), test_size=test_size, random_state=42)\n",
    "    else:\n",
    "        train_ents = alignment_dict.keys()\n",
    "    \n",
    "    S = np.empty((len(train_ents), emb_dim))\n",
    "    T = np.empty((len(train_ents), emb_dim))\n",
    "    if test_size > 0:\n",
    "        S_eval = np.empty((len(eval_ents), emb_dim))\n",
    "        T_eval = np.empty((len(eval_ents), emb_dim))\n",
    "\n",
    "    for i, key in tqdm(enumerate(train_ents), total=len(train_ents), desc='Computing S and T'):\n",
    "        S[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "        T[i] = entity2vec2[alignment_dict[key]] if isinstance(entity2vec2, dict) else entity2vec2.loc[alignment_dict[key]].values\n",
    "        \n",
    "    if test_size > 0:\n",
    "        for i, key in tqdm(enumerate(eval_ents), total=len(eval_ents), desc='Computing S_eval and T_eval'):\n",
    "            S_eval[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "            T_eval[i] = entity2vec2[alignment_dict[key]] if isinstance(entity2vec2, dict) else entity2vec2.loc[alignment_dict[key]].values\n",
    "        \n",
    "    print('\\nNow computing R...')\n",
    "    \n",
    "    t0 = time.time()\n",
    "    R, scale = orthogonal_procrustes(S/np.sqrt((S**2).sum()), T/np.sqrt((T**2).sum()), check_finite=True)\n",
    "    print('\\nCompleted after '+str(time.time()-t0)+' seconds')\n",
    "    print('scale: ', scale)\n",
    "    \n",
    "    if test_size > 0:\n",
    "        return S/np.sqrt((S**2).sum()), T/np.sqrt((T**2).sum()), S_eval/np.sqrt((S_eval**2).sum()), T_eval/np.sqrt((T_eval**2).sum()), R\n",
    "    else:\n",
    "        return S/np.sqrt((S**2).sum()), T/np.sqrt((T**2).sum()), R\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "obvious-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_aligned_entity_embedding_matrices(alignment_dict, entity2vec1, entity2vec2, emb_dim=200):\n",
    "    \"\"\"\n",
    "    Inputs the dictionary of aligned entities between two KGs and their corresponding embeddings, and returns the normalized embedding matrices of \n",
    "    \n",
    "    non-aligned entities\n",
    "    \"\"\"\n",
    "    A_neg_S = np.empty((len(entity2vec1)-len(alignment_dict), emb_dim))\n",
    "    keys = sorted(set(entity2vec1.keys() if isinstance(entity2vec1, dict) else entity2vec1.index)-set(alignment_dict.keys()))\n",
    "    for i, key in tqdm(enumerate(keys), total=A_neg_S.shape[0], desc='Computing A_neg_S...'):\n",
    "        A_neg_S[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "    \n",
    "    B_neg_T = np.empty((len(entity2vec2)-len(alignment_dict), emb_dim))\n",
    "    keys = sorted(set(entity2vec2.keys() if isinstance(entity2vec2, dict) else entity2vec2.index)-set(alignment_dict.values()))\n",
    "    for i, key in tqdm(enumerate(keys), total=B_neg_T.shape[0], desc='Computing B_neg_T...'):\n",
    "        B_neg_T[i] = entity2vec2[key] if isinstance(entity2vec2, dict) else entity2vec2.loc[key].values\n",
    "    \n",
    "    return A_neg_S/np.sqrt((A_neg_S**2).sum()), B_neg_T/np.sqrt((B_neg_T**2).sum())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-paste",
   "metadata": {},
   "source": [
    "## Evaluating Procrustes alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "biblical-domestic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 3370708/3370708 [00:32<00:00, 105310.01it/s]\n",
      "Computing S_eval and T_eval: 100%|██████████| 374524/374524 [00:02<00:00, 131021.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "\n",
      "Completed after 22.48607349395752 seconds\n",
      "scale:  0.4375346570394851\n"
     ]
    }
   ],
   "source": [
    "S, T, S_eval, T_eval, R = get_source_and_target_matrices(new_aligned_entity_dict, entity2vec_cal, entity2vec_db, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "accepted-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "approved-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_alignment_knn(S_eval, T_eval, R):\n",
    "    \"\"\"The function takes the evaluation sets, i.e. correct alignments that were left out, and returns the accuracy computed as the proportion\n",
    "    of correct alignment predictions\n",
    "    \n",
    "    \"\"\"\n",
    "    print('#'*50)\n",
    "    print('Evaluation started...')\n",
    "    print('#'*50)\n",
    "    model = NearestNeighbors(n_neighbors=1, n_jobs=-1)\n",
    "    print('Fitting...')\n",
    "    model.fit(S_eval@R)\n",
    "    print('Predicting...')\n",
    "    preds = model.kneighbors(T_eval, 1, return_distance=False)\n",
    "    preds = preds.reshape(-1,)\n",
    "    acc = (preds == np.arange(S_eval.shape[0])).astype(float).sum()\n",
    "    return acc / S_eval.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "supported-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_alignment(S_eval, T_eval, R, num_candidates=10):\n",
    "    \"\"\"The function takes the evaluation sets, i.e. correct alignments that were left out, and returns the accuracy computed as the proportion\n",
    "    of correct alignment predictions\n",
    "    \n",
    "    \"\"\"\n",
    "    print('#'*50)\n",
    "    print('Evaluation started...')\n",
    "    print('#'*50)\n",
    "    acc = 0\n",
    "    ids = list(range(S_eval.shape[0]))\n",
    "    for i in tqdm(range(S_eval.shape[0])):\n",
    "        s_i = S_eval[i][None, :]@R\n",
    "        rand_ids = list(set(random.sample(ids, k=num_candidates))-{i})\n",
    "        candidates = np.concatenate([T_eval[i][None, :], T_eval[rand_ids[:num_candidates-1]]], axis=0)\n",
    "        acc += ((candidates-s_i)**2).sum(1).squeeze().argmin() == 1\n",
    "    return acc / S_eval.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = evaluate_alignment(S_eval.astype(np.float16), T_eval.astype(np.float16), R.astype(np.float16))\n",
    "print('Accuracy on validation data: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "brief-vegetable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting...\n",
      "Predicting...\n",
      "Accuracy on validation data:  1.0\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_alignment_knn(S_eval.astype(np.float16), T_eval.astype(np.float16), R.astype(np.float16))\n",
    "print('Accuracy on validation data: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-monte",
   "metadata": {},
   "source": [
    "## Computing and storing universal embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del S, T, S_eval, T_eval, R\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_merged_entities = sorted(set(entity2vec_cal.keys())-set(new_aligned_entity_dict.keys())) +\\\n",
    "sorted(set(entity2vec_db.keys())-set(new_aligned_entity_dict.values())) + \\\n",
    "list(new_aligned_entity_dict.keys())\n",
    "with open('Caligraph_Dbpedia/list_merged_entities_cal_db.txt', 'w') as file:\n",
    "    file.write(','.join(list_merged_entities))\n",
    "del list_merged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "S, T, R = get_source_and_target_matrices(new_aligned_entity_dict, entity2vec_cal, entity2vec_db, test_size=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_neg_S, B_neg_T = get_non_aligned_entity_embedding_matrices(new_aligned_entity_dict, entity2vec_cal, entity2vec_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "del entity2vec_cal, entity2vec_db\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute every s_i as (s_i@R+t_i)/2\n",
    "S = (S@R + T)/2\n",
    "del T\n",
    "gc.collect()\n",
    "Universal_Emb = np.concatenate([A_neg_S@R, B_neg_T, S], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Caligraph_Dbpedia/Universal_Emb.npy', Universal_Emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "Universal_Emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-spending",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rising-reunion",
   "metadata": {},
   "source": [
    "# French and English Dbpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complimentary-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import procrustes\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import time, gc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "phantom-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "federal-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(full_embedding_path, entity_id_map):\n",
    "    print('Loading embeddings...')\n",
    "    model = torch.load(full_embedding_path, map_location='cpu')\n",
    "    with open(entity_id_map) as file:\n",
    "        entity_id_map = json.load(file)\n",
    "    ent_emb = pd.DataFrame(model.entity_embeddings._embeddings.weight.data.tolist(), index=list(entity_id_map.keys()))\n",
    "    return ent_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "about-institute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings...\n",
      "Loading embeddings...\n"
     ]
    }
   ],
   "source": [
    "fr_dbpedia_emb = load_embeddings('Fr_En_Dbpedia/Fr/embeddings/TransE/trained_model.pkl', 'Fr_En_Dbpedia/Fr/embeddings/TransE/entity_to_ids.json')\n",
    "eng_dbpedia_emb = load_embeddings('Fr_En_Dbpedia/En/embeddings/TransE/trained_model.pkl', 'Fr_En_Dbpedia/En/embeddings/TransE/entity_to_ids.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brown-allocation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009833</td>\n",
       "      <td>-0.012834</td>\n",
       "      <td>-0.115936</td>\n",
       "      <td>-0.040705</td>\n",
       "      <td>0.076594</td>\n",
       "      <td>-0.034350</td>\n",
       "      <td>-0.020555</td>\n",
       "      <td>0.042299</td>\n",
       "      <td>0.027486</td>\n",
       "      <td>-0.074162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050411</td>\n",
       "      <td>-0.071838</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>-0.057446</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.041489</td>\n",
       "      <td>0.122214</td>\n",
       "      <td>0.017487</td>\n",
       "      <td>0.109715</td>\n",
       "      <td>-0.065048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.021399</td>\n",
       "      <td>-0.031363</td>\n",
       "      <td>-0.058264</td>\n",
       "      <td>0.045010</td>\n",
       "      <td>0.084431</td>\n",
       "      <td>-0.033651</td>\n",
       "      <td>-0.048864</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.034992</td>\n",
       "      <td>-0.049416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083037</td>\n",
       "      <td>-0.063910</td>\n",
       "      <td>-0.010611</td>\n",
       "      <td>-0.039704</td>\n",
       "      <td>-0.009805</td>\n",
       "      <td>0.044853</td>\n",
       "      <td>-0.029519</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.093731</td>\n",
       "      <td>-0.015521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.086678</td>\n",
       "      <td>0.013267</td>\n",
       "      <td>-0.062660</td>\n",
       "      <td>0.040125</td>\n",
       "      <td>0.051002</td>\n",
       "      <td>-0.063431</td>\n",
       "      <td>-0.060855</td>\n",
       "      <td>-0.007261</td>\n",
       "      <td>0.036402</td>\n",
       "      <td>-0.072729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077436</td>\n",
       "      <td>-0.072368</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>-0.072700</td>\n",
       "      <td>-0.018492</td>\n",
       "      <td>0.030871</td>\n",
       "      <td>-0.049264</td>\n",
       "      <td>0.066449</td>\n",
       "      <td>0.063988</td>\n",
       "      <td>-0.029479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "0  -0.009833 -0.012834 -0.115936 -0.040705  0.076594 -0.034350 -0.020555   \n",
       "1  -0.021399 -0.031363 -0.058264  0.045010  0.084431 -0.033651 -0.048864   \n",
       "10  0.086678  0.013267 -0.062660  0.040125  0.051002 -0.063431 -0.060855   \n",
       "\n",
       "         7         8         9    ...       190       191       192       193  \\\n",
       "0   0.042299  0.027486 -0.074162  ...  0.050411 -0.071838  0.001301 -0.057446   \n",
       "1   0.000954  0.034992 -0.049416  ... -0.083037 -0.063910 -0.010611 -0.039704   \n",
       "10 -0.007261  0.036402 -0.072729  ... -0.077436 -0.072368 -0.044481 -0.072700   \n",
       "\n",
       "         194       195       196       197       198       199  \n",
       "0   0.001407  0.041489  0.122214  0.017487  0.109715 -0.065048  \n",
       "1  -0.009805  0.044853 -0.029519  0.105641  0.093731 -0.015521  \n",
       "10 -0.018492  0.030871 -0.049264  0.066449  0.063988 -0.029479  \n",
       "\n",
       "[3 rows x 200 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_dbpedia_emb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "above-madness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10500</th>\n",
       "      <td>-0.006989</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>-0.113241</td>\n",
       "      <td>0.046147</td>\n",
       "      <td>0.030751</td>\n",
       "      <td>-0.080907</td>\n",
       "      <td>-0.059351</td>\n",
       "      <td>-0.129297</td>\n",
       "      <td>0.073091</td>\n",
       "      <td>-0.028684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>-0.089282</td>\n",
       "      <td>-0.004109</td>\n",
       "      <td>-0.091981</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>-0.005688</td>\n",
       "      <td>-0.051136</td>\n",
       "      <td>-0.028319</td>\n",
       "      <td>-0.025681</td>\n",
       "      <td>-0.146335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10501</th>\n",
       "      <td>-0.011741</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>-0.141341</td>\n",
       "      <td>0.075984</td>\n",
       "      <td>0.083039</td>\n",
       "      <td>-0.029970</td>\n",
       "      <td>-0.032043</td>\n",
       "      <td>-0.016951</td>\n",
       "      <td>0.021821</td>\n",
       "      <td>0.040540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127512</td>\n",
       "      <td>-0.049333</td>\n",
       "      <td>-0.035813</td>\n",
       "      <td>-0.059700</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>-0.022301</td>\n",
       "      <td>0.016085</td>\n",
       "      <td>0.077748</td>\n",
       "      <td>-0.144073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10502</th>\n",
       "      <td>0.019575</td>\n",
       "      <td>0.049873</td>\n",
       "      <td>-0.130476</td>\n",
       "      <td>0.071612</td>\n",
       "      <td>0.063691</td>\n",
       "      <td>-0.046625</td>\n",
       "      <td>-0.059835</td>\n",
       "      <td>-0.057370</td>\n",
       "      <td>0.062840</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126775</td>\n",
       "      <td>-0.073543</td>\n",
       "      <td>-0.017385</td>\n",
       "      <td>-0.066693</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>-0.004180</td>\n",
       "      <td>-0.035554</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.059197</td>\n",
       "      <td>-0.198770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "10500 -0.006989  0.000777 -0.113241  0.046147  0.030751 -0.080907 -0.059351   \n",
       "10501 -0.011741  0.069580 -0.141341  0.075984  0.083039 -0.029970 -0.032043   \n",
       "10502  0.019575  0.049873 -0.130476  0.071612  0.063691 -0.046625 -0.059835   \n",
       "\n",
       "            7         8         9    ...       190       191       192  \\\n",
       "10500 -0.129297  0.073091 -0.028684  ... -0.147443 -0.089282 -0.004109   \n",
       "10501 -0.016951  0.021821  0.040540  ... -0.127512 -0.049333 -0.035813   \n",
       "10502 -0.057370  0.062840  0.015700  ... -0.126775 -0.073543 -0.017385   \n",
       "\n",
       "            193       194       195       196       197       198       199  \n",
       "10500 -0.091981  0.008184 -0.005688 -0.051136 -0.028319 -0.025681 -0.146335  \n",
       "10501 -0.059700  0.032912  0.008938 -0.022301  0.016085  0.077748 -0.144073  \n",
       "10502 -0.066693  0.021840 -0.004180 -0.035554  0.007543  0.059197 -0.198770  \n",
       "\n",
       "[3 rows x 200 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_dbpedia_emb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "wrapped-native",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19661, 200)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_dbpedia_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "serial-heart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19993, 200)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_dbpedia_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "twelve-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Fr_En_Dbpedia/ref_ent_ids') as file:\n",
    "    mapping = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accepting-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_to_eng_ids = dict(list(map(lambda x: x.strip('\\n').split('\\t'), mapping)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "strategic-louis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 13500/13500 [00:02<00:00, 5499.36it/s]\n",
      "Computing S_eval and T_eval: 100%|██████████| 1500/1500 [00:00<00:00, 5187.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "\n",
      "Completed after 0.10346341133117676 seconds\n",
      "scale:  0.9272847214147476\n"
     ]
    }
   ],
   "source": [
    "S, T, S_eval, T_eval, R = get_source_and_target_matrices(fr_to_eng_ids, fr_dbpedia_emb, eng_dbpedia_emb, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-failing",
   "metadata": {},
   "source": [
    "### Evaluate entity alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sought-concord",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:00<00:00, 11039.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data:  0.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_alignment(S_eval.astype(np.float32), T_eval.astype(np.float32), R.astype(np.float32))\n",
    "print('Accuracy on validation data: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "earlier-double",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting...\n",
      "Predicting...\n",
      "Accuracy on validation data:  0.018666666666666668\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_alignment_knn(S_eval.astype(np.float32), T_eval.astype(np.float32), R.astype(np.float32))\n",
    "print('Accuracy on validation data: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-guest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "competitive-eight",
   "metadata": {},
   "source": [
    "## Compute and store universal embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "outdoor-forge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of merged entities: 24654\n"
     ]
    }
   ],
   "source": [
    "## We now want true entity IRIs. We only have their key ids\n",
    "with open('Fr_En_Dbpedia/ent_ids_1') as file:\n",
    "    entity_names_map_fr = file.readlines()\n",
    "\n",
    "with open('Fr_En_Dbpedia/ent_ids_2') as file:\n",
    "    entity_names_map_eng = file.readlines()\n",
    "    \n",
    "id_to_name_fr = dict(list(map(lambda x: x.strip('\\n').split('\\t'), entity_names_map_fr)))\n",
    "id_to_name_eng = dict(list(map(lambda x: x.strip('\\n').split('\\t'), entity_names_map_eng)))\n",
    "\n",
    "true_merged_entity_names = list(map(id_to_name_fr.get, sorted(set(fr_dbpedia_emb.index)-set(fr_to_eng_ids.keys())))) + \\\n",
    "                           list(map(id_to_name_eng.get, sorted(set(eng_dbpedia_emb.index)-set(fr_to_eng_ids.values())))) + \\\n",
    "                           list(map(id_to_name_fr.get, list(fr_to_eng_ids.keys())))\n",
    "print(f'Total number of merged entities: {len(true_merged_entity_names)}')\n",
    "with open('Fr_En_Dbpedia/list_merged_entities_Fr_Eng_dbpedia.txt', 'w') as file:\n",
    "    file.write(','.join(true_merged_entity_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "imperial-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr_to_Eng_entity_names = dict(zip(list(map(id_to_name_fr.get, fr_to_eng_ids.keys())),\\\n",
    "                                 list(map(id_to_name_eng.get, fr_to_eng_ids.values()))))\n",
    "\n",
    "Eng_to_Fr_entity_names = {value:key for key,value in Fr_to_Eng_entity_names.items()}\n",
    "\n",
    "with open('Fr_En_Dbpedia/Fr_to_Eng_entity_names.json', 'w') as file:\n",
    "    json.dump(Fr_to_Eng_entity_names, file, ensure_ascii=False)\n",
    "    \n",
    "with open('Fr_En_Dbpedia/Eng_to_Fr_entity_names.json', 'w') as file:\n",
    "    json.dump(Eng_to_Fr_entity_names, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "latter-stake",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 15000/15000 [00:02<00:00, 5226.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "\n",
      "Completed after 0.11648726463317871 seconds\n",
      "scale:  0.9272167303554676\n"
     ]
    }
   ],
   "source": [
    "S, T, R = get_source_and_target_matrices(fr_to_eng_ids, fr_dbpedia_emb, eng_dbpedia_emb, test_size=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "specified-transformation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing A_neg_S...: 100%|██████████| 4661/4661 [00:00<00:00, 10899.23it/s]\n",
      "Computing B_neg_T...: 100%|██████████| 4993/4993 [00:00<00:00, 10936.88it/s]\n"
     ]
    }
   ],
   "source": [
    "A_neg_S, B_neg_T = get_non_aligned_entity_embedding_matrices(fr_to_eng_ids, fr_dbpedia_emb, eng_dbpedia_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "touched-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute every s_i as (s_i@R+t_i)/2\n",
    "S = (S@R + T)/2\n",
    "gc.collect()\n",
    "Universal_Emb = np.concatenate([A_neg_S@R, B_neg_T, S], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "assigned-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Fr_En_Dbpedia/Universal_Emb.npy', Universal_Emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-depth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unikge",
   "language": "python",
   "name": "unikge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
