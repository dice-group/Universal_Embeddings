{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "junior-orientation",
   "metadata": {},
   "source": [
    "## Using Shallom embeddings for Fr-En Dbpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "above-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy as sp\n",
    "import numpy as np\n",
    "#import matplotlib.pylab as pl\n",
    "#from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "#import ot\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "secret-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Shallom_EnFr_15K_V1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compatible-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnFr_shallom_embs_v1 = pd.read_csv('Shallom_EnFr_15K_V1/Shallom_entity_embeddings.csv')\n",
    "\n",
    "Fr_shallom_embs_v1 = EnFr_shallom_embs_v1[EnFr_shallom_embs_v1['Unnamed: 0'].apply(lambda x: 'fr.dbpedia.org' in x)]\n",
    "\n",
    "En_shallom_embs_v1 = EnFr_shallom_embs_v1.iloc[np.setdiff1d(np.arange(EnFr_shallom_embs_v1.shape[0]),\\\n",
    "                                                            np.array(Fr_shallom_embs_v1.index))].set_index('Unnamed: 0')\n",
    "\n",
    "Fr_shallom_embs_v1 = Fr_shallom_embs_v1.set_index('Unnamed: 0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "controlling-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OpenEA_dataset_v1.1/EN_FR_15K_V1/ent_links') as file:\n",
    "    en_to_fr_ents_v1 = file.read().strip().split('\\n')\n",
    "en_to_fr_ents_v1 = dict([line.split('\\t') for line in en_to_fr_ents_v1])\n",
    "\n",
    "with open('OpenEA_dataset_v1.1/EN_FR_15K_V1/721_5fold/1/test_links') as file:\n",
    "    test_set = file.read().strip().split('\\n')\n",
    "test_set = [line.split('\\t')[0] for line in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "outside-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_and_target_matrices(alignment_dict, entity2vec1, entity2vec2, given_test_set=None, emb_dim=200, return_test_set=True):\n",
    "    \"\"\"This function takes the dictionary of aligned entities between two KGs and their corresponding embeddings (as entity to vector dictionaries)\n",
    "    and returns S, T, S_test, T_test, and R defined as follows:\n",
    "    \n",
    "    -- S: Subset of the source embeddings, i.e. the matrix of aligned entity embeddings in the first knowledge graph\n",
    "    \n",
    "    -- T: Subset of the matrix of aligned entity embeddings in the second knowledge graph\n",
    "    \n",
    "    -- S_test and T_test are the embedding matrices corresponding to the lef-out SameAs links\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if return_test_set:\n",
    "        assert given_test_set is not None, \"given_test_set cannot be None if return_test_set is True\"\n",
    "        test_ents = given_test_set\n",
    "        train_ents = list(set(alignment_dict.keys())-set(test_ents))\n",
    "    else:\n",
    "        train_ents = alignment_dict.keys()\n",
    "    \n",
    "    S = np.empty((len(train_ents), emb_dim))\n",
    "    T = np.empty((len(train_ents), emb_dim))\n",
    "    if return_test_set:\n",
    "        S_test = np.empty((len(test_ents), emb_dim))\n",
    "        T_test = np.empty((len(test_ents), emb_dim))\n",
    "\n",
    "    for i, key in tqdm(enumerate(train_ents), total=len(train_ents), desc='Computing S and T'):\n",
    "        S[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "        T[i] = entity2vec2[alignment_dict[key]] if isinstance(entity2vec2, dict) else entity2vec2.loc[alignment_dict[key]].values\n",
    "        \n",
    "    if return_test_set:\n",
    "        for i, key in tqdm(enumerate(test_ents), total=len(test_ents), desc='Computing S_test and T_test'):\n",
    "            S_test[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "            T_test[i] = entity2vec2[alignment_dict[key]] if isinstance(entity2vec2, dict) else entity2vec2.loc[alignment_dict[key]].values\n",
    "    \n",
    "    if return_test_set:\n",
    "        return S, T, S_test, T_test\n",
    "    else:\n",
    "        return S, T\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "final-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 4500/4500 [00:00<00:00, 5598.58it/s]\n",
      "Computing S_test and T_test: 100%|██████████| 10500/10500 [00:01<00:00, 5703.03it/s]\n"
     ]
    }
   ],
   "source": [
    "S, T, S_test, T_test = get_source_and_target_matrices(en_to_fr_ents_v1, En_shallom_embs_v1, Fr_shallom_embs_v1, given_test_set=test_set, emb_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sacred-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "S, T = torch.FloatTensor(S), torch.FloatTensor(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daily-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C1 = sp.spatial.distance.cdist(S, S)\n",
    "#C2 = sp.spatial.distance.cdist(T, T)\n",
    "#\n",
    "#C1 /= C1.max()\n",
    "#C2 /= C2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "composed-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pl.figure()\n",
    "#pl.subplot(121)\n",
    "#pl.imshow(C1[:10, :10])\n",
    "#pl.colorbar()\n",
    "#pl.subplot(122)\n",
    "#pl.imshow(C2[:10, :10])\n",
    "#pl.colorbar()\n",
    "#pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reverse-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def loss_fun(x, y):\n",
    "#    return np.abs(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "technological-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = ot.unif(S.shape[0])\n",
    "#q = ot.unif(T.shape[0])\n",
    "#\n",
    "#t0 = time.time()\n",
    "##gw0, log0 = ot.gromov.gromov_wasserstein(\n",
    "##    C1, C2, p, q, 'square_loss', verbose=True, log=True)\n",
    "#gw0, log0 = ot.gromov.pointwise_gromov_wasserstein(C1, C2, p, q, loss_fun, max_iter=100,\n",
    "#                                                   log=True)\n",
    "#gw0 = gw0.toarray()\n",
    "#print('duration GW: ', time.time()-t0)\n",
    "#\n",
    "#t0 = time.time()\n",
    "##gw, log = ot.gromov.entropic_gromov_wasserstein(\n",
    "##    C1, C2, p, q, 'square_loss', epsilon=5e-4, log=True, verbose=True)\n",
    "#gw, log = ot.gromov.sampled_gromov_wasserstein(C1, C2, p, q, loss_fun, epsilon=0.1, max_iter=100,\n",
    "#                                                   log=True)\n",
    "#print('duration GW Entropic: ', time.time()-t0)\n",
    "#\n",
    "#print('Gromov-Wasserstein distances: ' + str(log0['gw_dist_estimated']))\n",
    "#print('Entropic Gromov-Wasserstein distances: ' + str(log['gw_dist_estimated']))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "arctic-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pl.figure(1, (10, 5))\n",
    "#\n",
    "#pl.subplot(1, 2, 1)\n",
    "##pl.imshow(gw0, cmap='jet')\n",
    "#pl.imshow(gw0, cmap='jet')\n",
    "#pl.title('Gromov Wasserstein')\n",
    "#\n",
    "#pl.subplot(1, 2, 2)\n",
    "##pl.imshow(gw, cmap='jet')\n",
    "#pl.imshow(gw, cmap='jet')\n",
    "#pl.title('Entropic Gromov Wasserstein')\n",
    "#\n",
    "#pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "atmospheric-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def evaluate_gw(gw, hits=[1, 5, 10]):\n",
    "#    def hits_k(ranks, k):\n",
    "#        return (ranks <= k-1).sum()/len(ranks)\n",
    "#    \n",
    "#    ids = np.arange(S.shape[0])\n",
    "#    ranks_ = gw.argsort(1)\n",
    "#    locs = np.where(ranks_ == ids.reshape(-1,1))[1] # (inverse) ranks of the diagonal elements of gw \n",
    "#    ranks = S.shape[0]-locs # ranks of the diagonal elements of gw\n",
    "#    \n",
    "#    result = []\n",
    "#    for k in tqdm(hits):\n",
    "#        result.append(f\"Hits@{k}: \"+str(hits_k(ranks, k)))\n",
    "#    print(', '.join(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-jacksonville",
   "metadata": {},
   "source": [
    "## Trying to build an efficient network architecture for entity alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "powered-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAB(nn.Module):\n",
    "    def __init__(self, dim_Q, dim_K, dim_V, num_heads, ln=False):\n",
    "        super(MAB, self).__init__()\n",
    "        self.dim_V = dim_V\n",
    "        self.num_heads = num_heads\n",
    "        self.fc_q = nn.Linear(dim_Q, dim_V)\n",
    "        self.fc_k = nn.Linear(dim_K, dim_V)\n",
    "        self.fc_v = nn.Linear(dim_K, dim_V)\n",
    "        if ln:\n",
    "            self.ln0 = nn.LayerNorm(dim_V)\n",
    "            self.ln1 = nn.LayerNorm(dim_V)\n",
    "        self.fc_o = nn.Linear(dim_V, dim_V)\n",
    "\n",
    "    def forward(self, Q, K):\n",
    "        Q = self.fc_q(Q)\n",
    "        K, V = self.fc_k(K), self.fc_v(K)\n",
    "\n",
    "        dim_split = self.dim_V // self.num_heads\n",
    "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
    "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
    "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
    "\n",
    "        A = torch.softmax(Q_.bmm(K_.transpose(1,2))/math.sqrt(self.dim_V), 2)\n",
    "        O = torch.cat((Q_ + A.bmm(V_)).split(Q.size(0), 0), 2)\n",
    "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
    "        O = O + F.relu(self.fc_o(O))\n",
    "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
    "        return O\n",
    "\n",
    "class SAB(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, num_heads, ln=False):\n",
    "        super(SAB, self).__init__()\n",
    "        self.mab = MAB(dim_in, dim_in, dim_out, num_heads, ln=ln)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.mab(X, X)\n",
    "\n",
    "class ISAB(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, num_heads, num_inds, ln=False):\n",
    "        super(ISAB, self).__init__()\n",
    "        self.I = nn.Parameter(torch.Tensor(1, num_inds, dim_out))\n",
    "        nn.init.xavier_uniform_(self.I)\n",
    "        self.mab0 = MAB(dim_out, dim_in, dim_out, num_heads, ln=ln)\n",
    "        self.mab1 = MAB(dim_in, dim_out, dim_out, num_heads, ln=ln)\n",
    "\n",
    "    def forward(self, X):\n",
    "        H = self.mab0(self.I.repeat(X.size(0), 1, 1), X)\n",
    "        return self.mab1(X, H)\n",
    "\n",
    "class PMA(nn.Module):\n",
    "    def __init__(self, dim, num_heads, num_seeds, ln=False):\n",
    "        super(PMA, self).__init__()\n",
    "        self.S = nn.Parameter(torch.Tensor(1, num_seeds, dim))\n",
    "        nn.init.xavier_uniform_(self.S)\n",
    "        self.mab = MAB(dim, dim, dim, num_heads, ln=ln)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.mab(self.S.repeat(X.size(0), 1, 1), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "monetary-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTransformer(nn.Module):\n",
    "    def __init__(self, kwargs):\n",
    "        super(SetTransformer, self).__init__()\n",
    "        self.name = 'SetTransformer'\n",
    "        self.enc = nn.Sequential(\n",
    "                ISAB(kwargs['input_size'], kwargs['proj_dim'], kwargs['num_heads'], kwargs['num_inds'], ln=kwargs['ln']),\n",
    "                ISAB(kwargs['proj_dim'], kwargs['proj_dim'], kwargs['num_heads'], kwargs['num_inds'], ln=kwargs['ln']))\n",
    "        \n",
    "        self.dec = SAB(kwargs['proj_dim'], kwargs['proj_dim'], kwargs['num_heads'], ln=kwargs['ln'])\n",
    "        \n",
    "        self.dec_score = nn.Sequential(PMA(kwargs['proj_dim'], kwargs['num_heads'], kwargs['num_seeds'], ln=kwargs['ln']),\n",
    "                                   nn.Linear(kwargs['proj_dim'], kwargs['output_size']), nn.Sigmoid())\n",
    "        self.output_size = kwargs[\"output_size\"]\n",
    "        \n",
    "    def forward(self, X):\n",
    "        enc_out = self.enc(X)\n",
    "        dec_out = self.dec(enc_out)\n",
    "        scores = self.dec_score(dec_out).reshape(-1, self.output_size)\n",
    "        return scores, dec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "agreed-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, data: list):\n",
    "        self.Source = data[0]\n",
    "        self.Target = data[1]\n",
    "        self.Label = data[2]\n",
    "        super(AlignDataSet, self).__init__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Source)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        source = self.Source[idx]\n",
    "        target = self.Target[idx]\n",
    "        return pad_sequence([source, target], batch_first=True, padding_value=0), self.Label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "speaking-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset, epochs, loss, num_workers=8, batch_size=128, lr=0.0001):\n",
    "    import copy\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for e in range(epochs):\n",
    "        Acc = 0.0\n",
    "        for x, y in tqdm(train_dataloader):\n",
    "            scores, hidden = model(x)\n",
    "            loss_val = loss(scores, y)\n",
    "            Acc += (y==scores.argmax(1)).sum()\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {e} ... Loss: {loss_val.item()}, Acc: {Acc/len(train_dataset)}\")\n",
    "        if Acc > best_acc:\n",
    "            best_acc = Acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    model.load_state_dict(best_weights)\n",
    "    torch.save(model, f\"{path}/SetTransformer_{round(best_acc.item(), 2)}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "southeast-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_dataset, num_workers=8, batch_size=128):\n",
    "    model.eval()\n",
    "    Acc = 0.0\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "    for x, y in tqdm(test_dataloader):\n",
    "        score, hidden = model(x)\n",
    "        Acc += (score.argmax(1)==y).sum().item()\n",
    "    print(\"Test acc: \", Acc/len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "increasing-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_false_matching(data):\n",
    "    corrupted_data = []\n",
    "    source, target = torch.empty(len(data[0]), data[0].shape[1]), torch.empty(len(data[0]), data[0].shape[1])\n",
    "    all_idx = set(range(len(data[0])))\n",
    "    for i in range(len(data[0])):\n",
    "        candidate_idx = list(all_idx-{i})\n",
    "        idx = random.choice(candidate_idx)\n",
    "        source[i] = data[0][i]\n",
    "        target[i] = data[1][idx]\n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "variable-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_source, corrupt_target = generate_false_matching([S,T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "massive-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.cat([torch.ones(corrupt_source.shape[0]), torch.zeros(corrupt_source.shape[0])], 0).to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "reliable-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "source, target = torch.cat([S, corrupt_source], 0), torch.cat([T, corrupt_target], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "impressed-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [source, target, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rental-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AlignDataSet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "senior-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"input_size\": 300, \"proj_dim\": 128, \"num_heads\": 4, \"num_inds\": 32, \"num_seeds\": 1, \"ln\": False, \"output_size\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acute-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SetTransformer(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hidden-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "residential-strength",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 ... Loss: 0.7186356782913208, Acc: 0.5106666684150696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ... Loss: 0.6512174010276794, Acc: 0.5827777981758118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 ... Loss: 0.5707482099533081, Acc: 0.7073333263397217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 ... Loss: 0.6459649801254272, Acc: 0.742111086845398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:14<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 ... Loss: 0.5666635036468506, Acc: 0.7632222175598145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 ... Loss: 0.5170491933822632, Acc: 0.7873333096504211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:16<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 ... Loss: 0.6000741720199585, Acc: 0.8013333082199097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 ... Loss: 0.491852343082428, Acc: 0.820888876914978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:14<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 ... Loss: 0.4250366687774658, Acc: 0.8206666707992554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:16<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 ... Loss: 0.39465102553367615, Acc: 0.8374444246292114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:16<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 ... Loss: 0.5241919159889221, Acc: 0.8386666774749756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:17<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 ... Loss: 0.5331332683563232, Acc: 0.8487777709960938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:17<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 ... Loss: 0.5322104096412659, Acc: 0.8572221994400024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:20<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 ... Loss: 0.462246835231781, Acc: 0.8572221994400024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:19<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 ... Loss: 0.5415084958076477, Acc: 0.8597777485847473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:19<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 ... Loss: 0.5274215340614319, Acc: 0.8658888936042786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 ... Loss: 0.4960044026374817, Acc: 0.874666690826416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:24<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 ... Loss: 0.38333410024642944, Acc: 0.8784444332122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 ... Loss: 0.3746541142463684, Acc: 0.8803333044052124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:20<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 ... Loss: 0.4960826337337494, Acc: 0.8845555782318115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:21<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 ... Loss: 0.5169781446456909, Acc: 0.886888861656189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:20<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 ... Loss: 0.5070103406906128, Acc: 0.8901110887527466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 ... Loss: 0.4139432907104492, Acc: 0.8881111145019531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:24<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 ... Loss: 0.4383591115474701, Acc: 0.8790000081062317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 ... Loss: 0.3699967861175537, Acc: 0.8912222385406494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:21<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 ... Loss: 0.41343212127685547, Acc: 0.8964444398880005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 ... Loss: 0.4459921419620514, Acc: 0.9007777571678162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:20<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 ... Loss: 0.4134364128112793, Acc: 0.9012222290039062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:20<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 ... Loss: 0.375165194272995, Acc: 0.8923333287239075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 ... Loss: 0.3222988247871399, Acc: 0.8901110887527466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:23<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 ... Loss: 0.3929559588432312, Acc: 0.8954444527626038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:23<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 ... Loss: 0.3883630931377411, Acc: 0.9006666541099548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:24<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 ... Loss: 0.35054296255111694, Acc: 0.9024444222450256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 ... Loss: 0.440331369638443, Acc: 0.9043333530426025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:25<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 ... Loss: 0.3911030888557434, Acc: 0.9046666622161865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:25<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 ... Loss: 0.33849066495895386, Acc: 0.907444417476654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 ... Loss: 0.38889169692993164, Acc: 0.9116666913032532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 ... Loss: 0.4707370698451996, Acc: 0.9095555543899536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 ... Loss: 0.37806442379951477, Acc: 0.910111129283905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:25<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 ... Loss: 0.38895100355148315, Acc: 0.9126666784286499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:24<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 ... Loss: 0.36179596185684204, Acc: 0.9114444255828857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:23<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 ... Loss: 0.42263928055763245, Acc: 0.9057777523994446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:24<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 ... Loss: 0.3132622241973877, Acc: 0.913777768611908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 ... Loss: 0.36324864625930786, Acc: 0.9190000295639038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:23<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 ... Loss: 0.3394232392311096, Acc: 0.9198889136314392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:21<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 ... Loss: 0.4632341265678406, Acc: 0.918666660785675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:24<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 ... Loss: 0.3633319139480591, Acc: 0.9150000214576721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:26<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 ... Loss: 0.36344391107559204, Acc: 0.9166666865348816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:26<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 ... Loss: 0.43465057015419006, Acc: 0.9155555367469788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:27<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 ... Loss: 0.3132687211036682, Acc: 0.9154444336891174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "type Tensor doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_906816/3531971811.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_906816/4235360653.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, epochs, loss, num_workers, batch_size, lr)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mbest_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{path}/SetTransformer_{round(best_acc, 2)}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: type Tensor doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "train(model, train_dataset, epochs=50, loss=loss, lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "exact-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_test, T_test = torch.FloatTensor(S_test), torch.FloatTensor(T_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "optical-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = torch.ones(S_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "grave-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = [S_test, T_test, test_labels]\n",
    "\n",
    "test_dataset = AlignDataSet(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "twelve-gothic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:02<00:00, 27.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc:  0.8485714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test(model, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-medium",
   "metadata": {},
   "source": [
    "<font color='blue'> ~85% accuracy on the test data !!! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-tiffany",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "least-casting",
   "metadata": {},
   "source": [
    "# The experiments with SetTransformer have finished here. Cells below are old implementations with the Procrustes approach!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-globe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-romania",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-combine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-forward",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eight-highway",
   "metadata": {},
   "source": [
    "## Fr-En Dbpedia 100K V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sticky-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnFr_shallom_embs_v2 = pd.read_csv('Shallom_EnFr_100K_V2/Shallom_entity_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "subtle-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr_shallom_embs_v2 = EnFr_shallom_embs_v2[EnFr_shallom_embs_v2['Unnamed: 0'].apply(lambda x: 'fr.dbpedia.org' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bound-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "En_shallom_embs_v2 = EnFr_shallom_embs_v2.iloc[np.setdiff1d(np.arange(EnFr_shallom_embs_v2.shape[0]),\\\n",
    "                                                            np.array(Fr_shallom_embs_v2.index))].set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "racial-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr_shallom_embs_v2 = Fr_shallom_embs_v2.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "external-korean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://dbpedia.org/resource/Sailing_to_Philadelphia</th>\n",
       "      <td>-0.107208</td>\n",
       "      <td>-0.463760</td>\n",
       "      <td>0.234986</td>\n",
       "      <td>-0.300843</td>\n",
       "      <td>-0.297771</td>\n",
       "      <td>0.157350</td>\n",
       "      <td>0.063645</td>\n",
       "      <td>0.219653</td>\n",
       "      <td>-0.373847</td>\n",
       "      <td>-0.517257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067203</td>\n",
       "      <td>-0.013326</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.097662</td>\n",
       "      <td>-0.050666</td>\n",
       "      <td>0.292337</td>\n",
       "      <td>-0.091069</td>\n",
       "      <td>0.141930</td>\n",
       "      <td>0.412293</td>\n",
       "      <td>0.111441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://dbpedia.org/resource/Horde_(band)</th>\n",
       "      <td>-0.031448</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.141856</td>\n",
       "      <td>-0.131928</td>\n",
       "      <td>-0.129672</td>\n",
       "      <td>0.056684</td>\n",
       "      <td>0.103640</td>\n",
       "      <td>0.017796</td>\n",
       "      <td>-0.080704</td>\n",
       "      <td>-0.920316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044921</td>\n",
       "      <td>0.069479</td>\n",
       "      <td>0.162442</td>\n",
       "      <td>0.144002</td>\n",
       "      <td>-0.108662</td>\n",
       "      <td>-0.412152</td>\n",
       "      <td>0.096725</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>-0.273330</td>\n",
       "      <td>-0.185328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://dbpedia.org/resource/Nessbeal</th>\n",
       "      <td>0.199559</td>\n",
       "      <td>-0.110438</td>\n",
       "      <td>0.225365</td>\n",
       "      <td>-0.145648</td>\n",
       "      <td>0.400099</td>\n",
       "      <td>-0.134547</td>\n",
       "      <td>0.287914</td>\n",
       "      <td>0.045707</td>\n",
       "      <td>0.731766</td>\n",
       "      <td>0.462888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217795</td>\n",
       "      <td>-0.313416</td>\n",
       "      <td>-0.295566</td>\n",
       "      <td>-0.239344</td>\n",
       "      <td>0.248340</td>\n",
       "      <td>0.115179</td>\n",
       "      <td>-0.185138</td>\n",
       "      <td>0.092450</td>\n",
       "      <td>-0.689202</td>\n",
       "      <td>0.140009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           0         1  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Sailing_to_Philadel... -0.107208 -0.463760   \n",
       "http://dbpedia.org/resource/Horde_(band)           -0.031448  0.542308   \n",
       "http://dbpedia.org/resource/Nessbeal                0.199559 -0.110438   \n",
       "\n",
       "                                                           2         3  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Sailing_to_Philadel...  0.234986 -0.300843   \n",
       "http://dbpedia.org/resource/Horde_(band)            0.141856 -0.131928   \n",
       "http://dbpedia.org/resource/Nessbeal                0.225365 -0.145648   \n",
       "\n",
       "                                                           4         5  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Sailing_to_Philadel... -0.297771  0.157350   \n",
       "http://dbpedia.org/resource/Horde_(band)           -0.129672  0.056684   \n",
       "http://dbpedia.org/resource/Nessbeal                0.400099 -0.134547   \n",
       "\n",
       "                                                           6         7  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Sailing_to_Philadel...  0.063645  0.219653   \n",
       "http://dbpedia.org/resource/Horde_(band)            0.103640  0.017796   \n",
       "http://dbpedia.org/resource/Nessbeal                0.287914  0.045707   \n",
       "\n",
       "                                                           8         9  ...  \\\n",
       "Unnamed: 0                                                              ...   \n",
       "http://dbpedia.org/resource/Sailing_to_Philadel... -0.373847 -0.517257  ...   \n",
       "http://dbpedia.org/resource/Horde_(band)           -0.080704 -0.920316  ...   \n",
       "http://dbpedia.org/resource/Nessbeal                0.731766  0.462888  ...   \n",
       "\n",
       "                                                         290       291  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Sailing_to_Philadel...  0.067203 -0.013326   \n",
       "http://dbpedia.org/resource/Horde_(band)            0.044921  0.069479   \n",
       "http://dbpedia.org/resource/Nessbeal                0.217795 -0.313416   \n",
       "\n",
       "                                                         292       293  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Sailing_to_Philadel...  0.009563  0.097662   \n",
       "http://dbpedia.org/resource/Horde_(band)            0.162442  0.144002   \n",
       "http://dbpedia.org/resource/Nessbeal               -0.295566 -0.239344   \n",
       "\n",
       "                                                         294       295  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Sailing_to_Philadel... -0.050666  0.292337   \n",
       "http://dbpedia.org/resource/Horde_(band)           -0.108662 -0.412152   \n",
       "http://dbpedia.org/resource/Nessbeal                0.248340  0.115179   \n",
       "\n",
       "                                                         296       297  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Sailing_to_Philadel... -0.091069  0.141930   \n",
       "http://dbpedia.org/resource/Horde_(band)            0.096725  0.008034   \n",
       "http://dbpedia.org/resource/Nessbeal               -0.185138  0.092450   \n",
       "\n",
       "                                                         298       299  \n",
       "Unnamed: 0                                                              \n",
       "http://dbpedia.org/resource/Sailing_to_Philadel...  0.412293  0.111441  \n",
       "http://dbpedia.org/resource/Horde_(band)           -0.273330 -0.185328  \n",
       "http://dbpedia.org/resource/Nessbeal               -0.689202  0.140009  \n",
       "\n",
       "[3 rows x 300 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "En_shallom_embs_v2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "precious-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OpenEA_dataset_v1.1/EN_FR_100K_V2/ent_links') as file:\n",
    "    en_to_fr_ents_v2 = file.read().strip().split('\\n')\n",
    "en_to_fr_ents_v2 = dict([line.split('\\t') for line in en_to_fr_ents_v2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "charitable-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OpenEA_dataset_v1.1/EN_FR_100K_V2/721_5fold/1/test_links') as file:\n",
    "    test_set = file.read().strip().split('\\n')\n",
    "test_set = [line.split('\\t')[0] for line in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "processed-communications",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 30000/30000 [00:05<00:00, 5478.10it/s]\n",
      "Computing S_eval and T_eval: 100%|██████████| 70000/70000 [00:12<00:00, 5533.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  6.116433867944566\n",
      "\n",
      "Completed after 18.63508653640747 seconds\n",
      "Alignment loss:  298776.82671862666\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _, _, _, S_test, T_test, R = get_source_and_target_matrices(en_to_fr_ents_v2,\\\n",
    "                                                En_shallom_embs_v2, Fr_shallom_embs_v2, given_test_set=test_set, emb_dim=300, test_size=0.2, shift=False, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "primary-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_alignment_knn(S_test, T_test, R, assume_known=True, hit_values=[1, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-receptor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "western-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 100000/100000 [00:19<00:00, 5137.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  6.113047898546291\n",
      "\n",
      "Completed after 0.695664644241333 seconds\n",
      "Alignment loss:  28446.94522432553\n"
     ]
    }
   ],
   "source": [
    "scale_S, scale_T, mean_S, mean_T, S, T, R = get_source_and_target_matrices(en_to_fr_ents_v2,\\\n",
    "                                                                                    En_shallom_embs_v2, Fr_shallom_embs_v2, emb_dim=300, test_size=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "asian-evidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing A_neg_S...: 0it [00:00, ?it/s]\n",
      "Computing B_neg_T...: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "A_neg_S, B_neg_T = get_non_aligned_entity_embedding_matrices(en_to_fr_ents_v2, En_shallom_embs_v2, \\\n",
    "                                                             Fr_shallom_embs_v2, scale_S, scale_T, mean_S, mean_T, emb_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "micro-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute every s_i as (s_i@R+t_i)/2\n",
    "S = (S@R + T)/2\n",
    "del T\n",
    "gc.collect()\n",
    "Universal_Emb = np.concatenate([A_neg_S@R, B_neg_T, S], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "paperback-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Shallom_EnFr_100K_V2/Universal_Emb.npy', Universal_Emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "everyday-confirmation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  100000\n"
     ]
    }
   ],
   "source": [
    "list_merged_entities = sorted(set(En_shallom_embs_v2.index)-set(en_to_fr_ents_v2.keys())) +\\\n",
    "sorted(set(Fr_shallom_embs_v2.index)-set(en_to_fr_ents_v2.values())) + \\\n",
    "list(en_to_fr_ents_v2.keys())\n",
    "print('Total: ', len(list_merged_entities))\n",
    "with open('Shallom_EnFr_100K_V2/list_merged_entities_db_fr_en.txt', 'w') as file:\n",
    "    file.write('\\t'.join(list_merged_entities))\n",
    "del list_merged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "measured-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Shallom_EnFr_100K_V2/english2french.json', 'w') as file:\n",
    "    json.dump(en_to_fr_ents_v2, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-oracle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "certified-booking",
   "metadata": {},
   "source": [
    "## Deutsch and English DBpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "entire-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import procrustes\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import time, gc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "gc.enable()\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expensive-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_and_target_matrices(alignment_dict, entity2vec1, entity2vec2, given_test_set=None, emb_dim=200, return_test_set=True):\n",
    "    \"\"\"This function takes the dictionary of aligned entities between two KGs and their corresponding embeddings (as entity to vector dictionaries)\n",
    "    and returns S, T, S_test, T_test, and R defined as follows:\n",
    "    \n",
    "    -- S: Subset of the source embeddings, i.e. the matrix of aligned entity embeddings in the first knowledge graph\n",
    "    \n",
    "    -- T: Subset of the matrix of aligned entity embeddings in the second knowledge graph\n",
    "    \n",
    "    -- S_test and T_test are the embedding matrices corresponding to the lef-out SameAs links\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if return_test_set:\n",
    "        assert given_test_set is not None, \"given_test_set cannot be None if return_test_set is True\"\n",
    "        test_ents = given_test_set\n",
    "        train_ents = list(set(alignment_dict.keys())-set(test_ents))\n",
    "    else:\n",
    "        train_ents = alignment_dict.keys()\n",
    "    \n",
    "    S = np.empty((len(train_ents), emb_dim))\n",
    "    T = np.empty((len(train_ents), emb_dim))\n",
    "    if return_test_set:\n",
    "        S_test = np.empty((len(test_ents), emb_dim))\n",
    "        T_test = np.empty((len(test_ents), emb_dim))\n",
    "\n",
    "    for i, key in tqdm(enumerate(train_ents), total=len(train_ents), desc='Computing S and T'):\n",
    "        S[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "        T[i] = entity2vec2[alignment_dict[key]] if isinstance(entity2vec2, dict) else entity2vec2.loc[alignment_dict[key]].values\n",
    "        \n",
    "    if return_test_set:\n",
    "        for i, key in tqdm(enumerate(test_ents), total=len(test_ents), desc='Computing S_test and T_test'):\n",
    "            S_test[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "            T_test[i] = entity2vec2[alignment_dict[key]] if isinstance(entity2vec2, dict) else entity2vec2.loc[alignment_dict[key]].values\n",
    "    \n",
    "    if return_test_set:\n",
    "        return S, T, S_test, T_test\n",
    "    else:\n",
    "        return S, T\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acquired-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_aligned_entity_embedding_matrices(alignment_dict, entity2vec1, entity2vec2, scale_S, scale_T, mean_S, mean_T, emb_dim=200):\n",
    "    \"\"\"\n",
    "    Inputs the dictionary of aligned entities between two KGs and their corresponding embeddings, and returns the normalized embedding matrices of \n",
    "    \n",
    "    non-aligned entities\n",
    "    \"\"\"\n",
    "    A_neg_S = np.empty((len(entity2vec1)-len(alignment_dict), emb_dim))\n",
    "    keys = sorted(set(entity2vec1.keys() if isinstance(entity2vec1, dict) else entity2vec1.index)-set(alignment_dict.keys()))\n",
    "    for i, key in tqdm(enumerate(keys), total=A_neg_S.shape[0], desc='Computing A_neg_S...'):\n",
    "        A_neg_S[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "    \n",
    "    B_neg_T = np.empty((len(entity2vec2)-len(alignment_dict), emb_dim))\n",
    "    keys = sorted(set(entity2vec2.keys() if isinstance(entity2vec2, dict) else entity2vec2.index)-set(alignment_dict.values()))\n",
    "    for i, key in tqdm(enumerate(keys), total=B_neg_T.shape[0], desc='Computing B_neg_T...'):\n",
    "        B_neg_T[i] = entity2vec2[key] if isinstance(entity2vec2, dict) else entity2vec2.loc[key].values\n",
    "        \n",
    "    return (A_neg_S-mean_S)/scale_S, (B_neg_T-mean_T)/scale_T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exterior-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_alignment_knn(S_test, T_test, R, assume_known=False, hit_values = [1, 3, 10], rotate=True):\n",
    "    \"\"\"The function takes the evaluation sets, i.e. correct alignments that were left out, and returns the hits@ and MRR results w.r.t. correct alignments\n",
    "    \n",
    "    --assume_known. A boolean variable. When set to True, the alignment results are computed using the fact that the test links are known\n",
    "    \n",
    "    \"\"\"\n",
    "    print('#'*50)\n",
    "    print('Evaluation started...')\n",
    "    print('#'*50)\n",
    "    model = NearestNeighbors(n_neighbors=S_test.shape[0], n_jobs=-1)\n",
    "    print('Fitting 1...')\n",
    "    model.fit(T_test)\n",
    "    print('Predicting 1...')\n",
    "    if assume_known:\n",
    "        if rotate:\n",
    "            preds = model.kneighbors((S_test@R+T_test)/2, n_neighbors=S_test.shape[0], return_distance=False)\n",
    "        else:\n",
    "            preds = model.kneighbors((S_test+T_test)/2, n_neighbors=S_test.shape[0], return_distance=False)\n",
    "    else:\n",
    "        if rotate:\n",
    "            preds = model.kneighbors(S_test@R, n_neighbors=S_test.shape[0], return_distance=False)\n",
    "        else:\n",
    "            preds = model.kneighbors(S_test, n_neighbors=S_test.shape[0], return_distance=False)\n",
    "    Hits1 = np.zeros(len(hit_values))\n",
    "    MRR1 = 0.0\n",
    "    for i in tqdm(range(S_test.shape[0]), total=S_test.shape[0]):\n",
    "        pred_idx = (preds[i]==i).nonzero()[0][0] # if i in preds[i] else S_test.shape[0]\n",
    "        MRR1 += (1./(pred_idx+1))\n",
    "        for j in range(len(Hits1)):\n",
    "            if pred_idx < hit_values[j]:\n",
    "                Hits1[j] += 1.0/S_test.shape[0]\n",
    "    MRR1 = MRR1/S_test.shape[0]\n",
    "    \n",
    "    model = NearestNeighbors(n_neighbors=S_test.shape[0], n_jobs=-1)\n",
    "    print('\\nFitting 2...')\n",
    "    if assume_known:\n",
    "        if rotate:\n",
    "            model.fit((S_test@R+T_test)/2)\n",
    "        else:\n",
    "            model.fit((S_test+T_test)/2)\n",
    "    else:\n",
    "        if rotate:\n",
    "            model.fit(S_test@R)\n",
    "        else:\n",
    "            model.fit(S_test)\n",
    "    print('Predicting 2...')\n",
    "    preds = model.kneighbors(T_test, n_neighbors=S_test.shape[0], return_distance=False)\n",
    "    Hits2 = np.zeros(len(hit_values))\n",
    "    MRR2 = 0.0\n",
    "    for i in tqdm(range(S_test.shape[0]), total=S_test.shape[0]):\n",
    "        pred_idx = (preds[i]==i).nonzero()[0][0] # if i in preds[i] else S_test.shape[0]\n",
    "        MRR2 += (1./(pred_idx+1))\n",
    "        for j in range(len(Hits2)):\n",
    "            if pred_idx < hit_values[j]:\n",
    "                Hits2[j] += 1.0/S_test.shape[0]\n",
    "    MRR2 = MRR2/S_test.shape[0]\n",
    "    \n",
    "    Hits = (Hits1+Hits2)/2\n",
    "    MRR = (MRR1+MRR2)/2\n",
    "    print()\n",
    "    print(', '.join([f'Hits@{hit_values[it]}: {Hits[it]}' for it in range(len(Hits))]+[f'MRR: {MRR}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-viking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "formed-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(path):\n",
    "    import torch\n",
    "    import dask.dataframe as dd\n",
    "    entity_embeddings=torch.load(f'{path}/Shallom_entity_embeddings.pt').detach().numpy()\n",
    "    entity_to_idx = dd.read_parquet(f'{path}/entity_to_idx.gzip').compute()\n",
    "    df = dd.from_array(entity_embeddings).compute()\n",
    "    df=df.set_index(entity_to_idx.index)\n",
    "    df.head()\n",
    "    df.to_csv(f'{path}/Shallom_entity_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alpine-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [\"Experiments/EN_DE_15K_V1\", \"Experiments/EN_DE_15K_V2\", \"Experiments/EN_DE_100K_V1\", \"Experiments/EN_DE_100K_V2\"]:\n",
    "    export_to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-component",
   "metadata": {},
   "source": [
    "### 15k v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "superb-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnDe_shallom_embs = pd.read_csv('Experiments/EN_DE_15K_V1/Shallom_entity_embeddings.csv')\n",
    "\n",
    "De_shallom_embs = EnDe_shallom_embs[EnDe_shallom_embs['Unnamed: 0'].apply(lambda x: 'de.dbpedia.org' in x)]\n",
    "\n",
    "En_shallom_embs = EnDe_shallom_embs.iloc[np.setdiff1d(np.arange(EnDe_shallom_embs.shape[0]),\\\n",
    "                                                            np.array(De_shallom_embs.index))].set_index('Unnamed: 0')\n",
    "\n",
    "De_shallom_embs = De_shallom_embs.set_index('Unnamed: 0')\n",
    "\n",
    "with open('OpenEA_dataset_v1.1/EN_DE_15K_V1/ent_links') as file:\n",
    "    en_to_de_ents = file.read().strip().split('\\n')\n",
    "en_to_de_ents = dict([line.split('\\t') for line in en_to_de_ents])\n",
    "\n",
    "with open('OpenEA_dataset_v1.1/EN_DE_15K_V1/721_5fold/1/test_links') as file:\n",
    "    test_set = file.read().strip().split('\\n')\n",
    "test_set = [line.split('\\t')[0] for line in test_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "simplified-language",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "De_shallom_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "immune-consensus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 4500/4500 [00:00<00:00, 5409.59it/s]\n",
      "Computing S_eval and T_eval: 100%|██████████| 10500/10500 [00:01<00:00, 5479.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  0.05050015345675206\n",
      "\n",
      "Completed after 3.037355422973633 seconds\n",
      "Alignment loss:  7.813596754606659\n",
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting 1...\n",
      "Predicting 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10500/10500 [00:00<00:00, 45059.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2...\n",
      "Predicting 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10500/10500 [00:00<00:00, 44068.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hits@1: 0.41747619047618023, Hits@5: 0.5862380952381306, Hits@10: 0.6490952380953084, MRR: 0.49776320692690734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _, _, _, S_test, T_test, R = get_source_and_target_matrices(en_to_de_ents,\\\n",
    "                                                En_shallom_embs, De_shallom_embs, given_test_set=test_set, emb_dim=300, test_size=0.2, scale=False, shift=False)\n",
    "\n",
    "evaluate_alignment_knn(S_test, T_test, R, assume_known=True, hit_values=[1, 5, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-musical",
   "metadata": {},
   "source": [
    "## 15k v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "unlikely-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnDe_shallom_embs = pd.read_csv('Experiments/EN_DE_15K_V2/Shallom_entity_embeddings.csv')\n",
    "\n",
    "De_shallom_embs = EnDe_shallom_embs[EnDe_shallom_embs['Unnamed: 0'].apply(lambda x: 'de.dbpedia.org' in x)]\n",
    "\n",
    "En_shallom_embs = EnDe_shallom_embs.iloc[np.setdiff1d(np.arange(EnDe_shallom_embs.shape[0]),\\\n",
    "                                                            np.array(De_shallom_embs.index))].set_index('Unnamed: 0')\n",
    "\n",
    "De_shallom_embs = De_shallom_embs.set_index('Unnamed: 0')\n",
    "\n",
    "with open('OpenEA_dataset_v1.1/EN_DE_15K_V2/ent_links') as file:\n",
    "    en_to_de_ents = file.read().strip().split('\\n')\n",
    "en_to_de_ents = dict([line.split('\\t') for line in en_to_de_ents])\n",
    "\n",
    "with open('OpenEA_dataset_v1.1/EN_DE_15K_V2/721_5fold/1/test_links') as file:\n",
    "    test_set = file.read().strip().split('\\n')\n",
    "test_set = [line.split('\\t')[0] for line in test_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "statistical-springfield",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 4500/4500 [00:00<00:00, 5797.15it/s]\n",
      "Computing S_eval and T_eval: 100%|██████████| 10500/10500 [00:01<00:00, 5406.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  0.04797353058639573\n",
      "\n",
      "Completed after 0.21141839027404785 seconds\n",
      "Alignment loss:  7.12450207466435\n",
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting 1...\n",
      "Predicting 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10500/10500 [00:00<00:00, 46697.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2...\n",
      "Predicting 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10500/10500 [00:00<00:00, 45976.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hits@1: 0.46542857142857996, Hits@5: 0.6234285714286275, Hits@10: 0.6857619047619955, MRR: 0.5412170755634034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _, _, _, S_test, T_test, R = get_source_and_target_matrices(en_to_de_ents,\\\n",
    "                                                En_shallom_embs, De_shallom_embs, given_test_set=test_set, emb_dim=300, test_size=0.2, scale=False, shift=False)\n",
    "\n",
    "evaluate_alignment_knn(S_test, T_test, R, assume_known=True, hit_values=[1, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "constant-barcelona",
   "metadata": {},
   "source": [
    "### 100k v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "imported-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnDe_shallom_embs = pd.read_csv('Experiments/EN_DE_100K_V1/Shallom_entity_embeddings.csv')\n",
    "\n",
    "De_shallom_embs = EnDe_shallom_embs[EnDe_shallom_embs['Unnamed: 0'].apply(lambda x: 'de.dbpedia.org' in x)]\n",
    "\n",
    "En_shallom_embs = EnDe_shallom_embs.iloc[np.setdiff1d(np.arange(EnDe_shallom_embs.shape[0]),\\\n",
    "                                                            np.array(De_shallom_embs.index))].set_index('Unnamed: 0')\n",
    "\n",
    "De_shallom_embs = De_shallom_embs.set_index('Unnamed: 0')\n",
    "\n",
    "with open('OpenEA_dataset_v1.1/EN_DE_100K_V1/ent_links') as file:\n",
    "    en_to_de_ents = file.read().strip().split('\\n')\n",
    "en_to_de_ents = dict([line.split('\\t') for line in en_to_de_ents])\n",
    "\n",
    "with open('OpenEA_dataset_v1.1/EN_DE_100K_V1/721_5fold/1/test_links') as file:\n",
    "    test_set = file.read().strip().split('\\n')\n",
    "test_set = [line.split('\\t')[0] for line in test_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caring-moscow",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 30000/30000 [00:05<00:00, 5474.18it/s]\n",
      "Computing S_eval and T_eval: 100%|██████████| 70000/70000 [00:12<00:00, 5598.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  0.021902208641113658\n",
      "\n",
      "Completed after 18.421804189682007 seconds\n",
      "Alignment loss:  8.544725213632967\n",
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting 1...\n",
      "Predicting 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70000/70000 [00:06<00:00, 11287.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2...\n",
      "Predicting 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70000/70000 [00:06<00:00, 10155.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hits@1: 0.2834999999999413, Hits@5: 0.4085714285711827, Hits@10: 0.46552857142828574, MRR: 0.3456914632419348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _, _, _, S_test, T_test, R = get_source_and_target_matrices(en_to_de_ents,\\\n",
    "                                                En_shallom_embs, De_shallom_embs, given_test_set=test_set, emb_dim=300, test_size=0.2, shift=False, scale=False)\n",
    "\n",
    "evaluate_alignment_knn(S_test, T_test, R, assume_known=True, hit_values=[1, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nuclear-camel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 100000/100000 [00:18<00:00, 5528.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  0.021967541711728614\n",
      "\n",
      "Completed after 19.402446746826172 seconds\n",
      "Alignment loss:  62694.90656351184\n"
     ]
    }
   ],
   "source": [
    "scale_S, scale_T, mean_S, mean_T, S, T, R = get_source_and_target_matrices(en_to_de_ents,\\\n",
    "                                                En_shallom_embs, De_shallom_embs, given_test_set=test_set, emb_dim=300, test_size=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "motivated-qualification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute every s_i as (s_i@R+t_i)/2\n",
    "S = (S@R + T)/2\n",
    "del T\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--es_index\", nargs='+', type=str, default=[\"DBP_EN_FR_15K\", \"DBP_EN_FR_100K\", \"DBP_EN_DE_100K\"], \\\n",
    "                    help=\"Preferred dataset name on Elastic Search\")\n",
    "parser.add_argument(\"--data_folder\", nargs='+', type=str, default=[\"Shallom_EnFr_15K_V1/\", \"Shallom_EnFr_100K_V1/\", \"Experiments/EN_DE_100K_V1/\"],\\\n",
    "                   help=\"Names of folders where universal embeddings are located\")\n",
    "parser.add_argument(\"--max_docs\", type=int, default=10000, help=\"Batch size of documents to upload\")\n",
    "parser.add_argument(\"--password\", type=str, default=None, help=\"Password to upload or delete data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "therapeutic-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Experiments/EN_DE_100K_V1//Universal_Emb.npy', S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "potential-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Experiments/EN_DE_100K_V1/list_merged_entities_db_en_de.txt', 'w') as file:\n",
    "    file.write('\\t'.join(en_to_de_ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "residential-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Experiments/EN_DE_100K_V1/english2german.json', 'w') as file:\n",
    "    json.dump(en_to_de_ents, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-young",
   "metadata": {},
   "source": [
    "### 100k v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "remarkable-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnDe_shallom_embs = pd.read_csv('Experiments/EN_DE_100K_V2/Shallom_entity_embeddings.csv')\n",
    "\n",
    "De_shallom_embs = EnDe_shallom_embs[EnDe_shallom_embs['Unnamed: 0'].apply(lambda x: 'de.dbpedia.org' in x)]\n",
    "\n",
    "En_shallom_embs = EnDe_shallom_embs.iloc[np.setdiff1d(np.arange(EnDe_shallom_embs.shape[0]),\\\n",
    "                                                            np.array(De_shallom_embs.index))].set_index('Unnamed: 0')\n",
    "De_shallom_embs = De_shallom_embs.set_index('Unnamed: 0')\n",
    "\n",
    "with open('OpenEA_dataset_v1.1/EN_DE_100K_V2/ent_links') as file:\n",
    "    en_to_de_ents = file.read().strip().split('\\n')\n",
    "en_to_de_ents = dict([line.split('\\t') for line in en_to_de_ents])\n",
    "\n",
    "with open('OpenEA_dataset_v1.1/EN_DE_100K_V2/721_5fold/1/test_links') as file:\n",
    "    test_set = file.read().strip().split('\\n')\n",
    "test_set = [line.split('\\t')[0] for line in test_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "concerned-annex",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 30000/30000 [00:05<00:00, 5143.77it/s]\n",
      "Computing S_eval and T_eval: 100%|██████████| 70000/70000 [00:13<00:00, 5180.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  0.02760568790057487\n",
      "\n",
      "Completed after 19.92166757583618 seconds\n",
      "Alignment loss:  14.747715207779663\n",
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting 1...\n",
      "Predicting 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70000/70000 [00:06<00:00, 11384.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2...\n",
      "Predicting 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70000/70000 [00:12<00:00, 5568.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hits@1: 0.49427142857128803, Hits@5: 0.6583214285713545, Hits@10: 0.7198214285714842, MRR: 0.5721232082416863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _, _, _, S_test, T_test, R = get_source_and_target_matrices(en_to_de_ents,\\\n",
    "                                                En_shallom_embs, De_shallom_embs, given_test_set=test_set, emb_dim=300, test_size=0.2, shift=False, scale=False)\n",
    "\n",
    "evaluate_alignment_knn(S_test, T_test, R, assume_known=True, hit_values=[1, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-street",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-peace",
   "metadata": {},
   "source": [
    "### Scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "touched-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "taken-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = [[4.3, 8.3, 12.9, 17.1], [329, 300.6], [350.8, 1084.5]]\n",
    "MRR = [[0.47, 0.43, 0.29, 0.40], [0.35, 0.33], [0.04, 0.04]]\n",
    "x_axis = [\"50K\", \"100K\", \"150K\", \"200K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "latin-kernel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training time')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEGCAYAAACZ0MnKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqkElEQVR4nO3de5xW4/7/8ddnUg0dpeksnXypkDQpW7YibdRGFLWdoqQ2NmU7H/PdTmnHZmfjS3LYig50IgohNr9dcsy26YBRlKhUpjLz+f2x1kwz08w9q2buWXN4Px+P+7HmXtc6fO57zb0+97que12XuTsiIiJRpMQdgIiIVBxKGiIiEpmShoiIRKakISIikSlpiIhIZHvFHUCyNWzY0Fu1ahV3GCIiFcqSJUt+cPe0gvMrfdJo1aoVixcvjjsMEZEKxcy+Kmy+qqdERCQyJQ0REYlMSUNERCKr9G0aIlL+7dixg4yMDDIzM+MOpcpJTU2lRYsWVK9ePdLyShoiEruMjAzq1KlDq1atMLO4w6ky3J3169eTkZFB69atI62j6ikRiV1mZib77befEkYZMzP222+/3brCU9IQkXJBCSMeu/u+K2lIxZH1K8y7DjZmxB2JSJWlpCEVx8I74d0HYdXbcUcilcyqVasws9xHgwYNGDRoEOvXr487tHxWr17NrbfeygsvvBBbDEoaUjF8sQDeGgedz4FOZ8UdjVRSnTt35plnnqFXr148++yzXH311bssk5WVVeL9/Prrr3u03urVqxkzZoyShkhCG7+FGRdBo45w0j1xRyOVWLNmzRg8eDB/+ctfAHjvvfdo1aoVtWrV4o9//CP16tXj448/ZtGiRXTr1o3atWvTrl07HnnkkdxtPPXUU3Ts2JG9996btm3bsnLlShYuXIiZcfLJJ3PkkUfSvXt3Jk2ahJkxbtw4APr164eZsWrVKtauXcvxxx9P7dq1qVu3Lt26dWPdunV07doVgCeeeAIzY9KkSWzcuJELL7yQRo0a0bBhQ4YPH86WLVsAuPXWW2ncuDGpqam0a9eOZ555psTvkX5yK+Vb1g6YdiFkbYczn4Aa+8QdkSTZmNmfsmz1plLdZodmdbnl9x2LXW7Hjh2sW7cu95t8y5YtWbZsGVu3bmX16tWMGzeOtLQ0jjvuOGrUqMG4ceN48sknufjii2nXrh3VqlXjvPPO43/+53+4//77WbVqVb6rigULFjBmzBhatmzJjh07iozjn//8J6+99ho333wzLVq0YPHixWRlZXH77bdzww038Nvf/paRI0fSrVs3rrjiCp5++mlGjRpFSkoK99xzD3Xq1OHGG29kzJgx9OrViyFDhrBixQqys7NL/F4qaUj59upt8M27cMZj0PDAuKORSu6VV16hUaNGADRv3pw77riD0047DQi+3derV485c+bw008/cf311zNixAjatm1Lnz59eOmll3K3M378ePr27Zv7/NtvvwWCq4nrrrsOgEmTJhUZx4EHBv/rr776Kj169OCss86iSZMm9OnThxtuuIHWrVszaNAgAObMmcOvv/7KPffsvAqfP38+d911F02aNOHzzz9n0aJFHHnkkZx++uklfo+UNKT8+vwleOd+SL8QDh0QdzRSRqJcESRLt27duP3222nQoAEdOnSgZs2aANSqVYt69erlWzbnp6q785PVZs2a5f5drVo1YGf7xoYNG3LL+vXrx7vvvsv8+fOZN28ed999N/Pnz2ffffctdLtNmjThqaeeyn1es2ZNqlevzocffsj06dNZunQpI0aMYOHChTz99NOR4y2MkoaUTxu+hudHQJPD4Hd3xh2NVBENGzbk+OOPT7jMUUcdxb777stjjz3G/vvvn3uyPvnkk0lJSWHcuHGMHj2a1atX89VXX3H++ecXup2ccX7mzp3Lfvvtx7vvvptbNm3aND788EPatWtHx44defvtt1m9ejVt2rQBYOnSpUyePJkTTjiBfv36MWnSJGbNmkWnTp1YsmQJKSkpHH744Vx11VX85je/IT09nWeeeYbVq1eX/E1y90r96NKli0sFs2Ob+yO93O9o4b5+edzRSBlYtmxZrPtfuXKlA963b99dyg444ACvVatWvnlvvfWWH3nkkb7PPvt427Zt/eGHH84te/LJJ719+/Zes2ZNb9Omja9YscJff/11B/ySSy7JXS47O9sHDx7stWvX9hNPPNG7devmgK9cudLnzp3r7du399TUVK9fv76fddZZvmXLFnd3/8Mf/uCpqakO+FtvveUbNmzwYcOGeePGjb1WrVp+xBFH+OTJk33r1q1+7LHHev369b1mzZp++OGH+9tvv13o6y/s/QcWeyHnVAvKKq/09HTXIEwVzLzrgvsxznwSOpwadzRSBj777DPat28fdxhVVmHvv5ktcff0gsvqJ7dSviybFSSMbiOUMETKISUNKT9+XAEzL4VmR8AJ/xt3NCJSCCUNKR92ZMLUIWDAwEmwV42YAxKRwujXU1I+vHIDrPkQBk2GfQ+IOxoRKULSrjTM7H4z+97M3Mzm5Jnf3szeMbNtZva5mfXJU3a0mX0Ulr1vZkfkKTvNzL40s0wzW2hm0UYMkfLvk+nw70fhN5fBwSfHHY2IJJDs6qkphcybDBwMjAZ2AFPNrJ6ZpQLTgTrAKKAxMM3MqplZk3Bbm4CrgC7AE0mOXcrCD1/CrD/B/t3g+FvijkZEipG0pOHufwLuzTvPzDoDnYDJ7j4BGA/UBQYAJxEkigfd/UHgMaA10BMYDNQE7nT3B4DngWPMrG2y4pcysOMXmHo+VKsBAyZCtWhjFIskw5YtW7jyyis54IADqFGjBk2bNuXUU0/l66+/BmDChAm0b9+emjVr0qxZM0aMGAEEnQKaGe3atcvtAbdnz56YGT/88EOR+5s7d25uV+wvv/xy7vyczg0vvfTSyNsqS2XdEJ5TpfRtOM0ZTadNCcp2YWbDzWyxmS1et25diYOWJHnpavj+Ezj9EajXIu5opApzd/r27cv48eNp06YN999/P5dffjnff/89X3/9NbfccguXXnopWVlZ/PWvf2XUqFF89NFH+baxfPlynn322cj7fPbZZ3OTxnPPPVfkcjfffDOTJ0+mbt26e/z6SlPcv55K1GnLnpbh7o+4e7q7p6elpe1ZZJJcH06B95+EY66EA0+IOxqp4l577TXeeOMN2rdvz4IFCxgxYgTXXnst7777Lp07d2bs2LHUqFGDBQsWcOmll3LVVVexaNGifNuoW7cud911F1FumN62bRuzZs2ie/fudOvWjeeff77IXm9vu+02Bg8ezKZNm3B3rrzySurXr0/37t3p378/ZsbChQuBoB+sAw88kLPPPpt69erRp08ftm7dWuL3J6+y/vXUynCa87WyeThdAfyYoKx2gjKpaNb+B+aMggN6QM/r445GypuXroXvPi7dbTY5FE66q8jiJUuWANCnTx+qVatGZmYmmzdvBmDZsmVkZmbSqVMnWrZsmbtOSkr+79wjRoxg7NixzJ49O9/8rVu35p64U1NTqV27NvPmzWPjxo0MGDAAd+fPf/4z8+fP5+STE/8QZPbs2YwfP54ePXpw5pln5vaYm9eXX35J//79Oeqoo3j55ZeZPn065557bsLt7o5k/nqqL5AzxNr+ZjYM2Ax8BAwys0sIGsN/JmgAfwlYC4w0s5HAUGAVsJCgEXw7cI2ZXQb0Bxa5+/JkxS9Jsn1L0I5RfR8441Gopl99S/wK9lj70EMPkZaWRlpaGnfffXekbXTt2pXevXtz5535O9gcO3Zs7rZy2ilyqqO6dOlCly5dACJVbb3++usA3HLLLVx22WWceuquvSY0bdqUsWPHMmTIECAYyrY0JfMTexVwbPj3YcD/ARcAfwAeJWgE/wo40903AJjZQGAC8DfgU+Aid88C1pjZYOAeYBzwXrgtqUjcYe6VsO5zOPd5qNs07oikPEpwRZAsOSfuV199FXfnjDPO4KeffuK2226jQ4cOvPbaa3z22WdkZGTQokVQ4ZGdnb3L1cb111/Pcccdl6/94bzzzqNHjx5A0DV6ZmYms2bNAoJG7hwzZ85k+/btkeJN1B17gwYNANhrr+D0XhrD0+aVtKTh7j0TFB9VxDpvAocWUTYDmFHyyCQ2S5+GDyfDsddC215xRyOSq1evXvTs2ZOFCxdy0kknMXDgQNasWQMEY2lcc801jBkzht69e3PZZZexbds2ZsyYsUu7Rq9evejevXu+bs7btGmT26U5wIwZM9i8eTNDhw6lX79+QFDtNHHiRObNm5ewwbtXr17cd9993HbbbSxbtoyZM2eW5tsQieoGpGx89wm8+GdofSwce3Xc0YjkY2bMnj2bm266ialTp/Laa6/RuHFjBgwYQN++fenatSsNGzZkwoQJjBo1in333ZdTTjml0G1df/31RZbBzmqokSNH5l7hNGvWjIkTJ/Lcc88xbNiwItf9/e9/z+jRo5k4cSJZWVn06NGDl19+mfr16+/5i99N6hpdkm/bz/BIz2A6YhHUbhR3RFLOqGv06MaPH89hhx3Gd999x+WXX87ee+/N8uXLc0cZ3BO70zW6rjQkudxh9uVBD7bnz1bCECmhWbNmceONN1KjRg3S09O55557SpQwdpeShiTX4olB31LH3QStesQdjUiFl3NPRlzivrlPKrPVH8C8a6Fdb+gxOu5opJyr7FXl5dXuvu9KGpIcmRuD+zFqpUH/RyBF/2pStNTUVNavX6/EUcbcnfXr15Oamhp5HVVPSelzD0bg2/ANXPAi1Nov7oiknGvRogUZGRmor7iyl5qamnvvSRRKGlL63nsYPpsVDNnasnvc0UgFUL16dVq31hA5FYHqDKR0ZSyBV26E/zkpGFRJRCoVJQ0pPb/8FIzzXacpnPYgJOjqQEQqJlVPSelwhxf+CD+vgQtfhn0axB2RiCSBkoaUjn/9HT5/EU68G1p0iTsaEUkSVU9JyX39Hsy/BdqfAt0ujjsaEUkiJQ0pmS3rYdoFUH9/OPXvascQqeRUPSV7Ljsbnh8OW9bB0PmQWi/uiEQkyZQ0ZM+9fS98uQD6/hWaHR53NCJSBlQ9JXtm1SJ47S9wyBmQPjTuaESkjChpyO7bvBamDYUGbeD3f1M7hkgVouop2T3ZWTDjIsjcAOdMh5p14o5IRMqQkobsnjfvgRUL4ZQHoMkhcUcjImVM1VMS3YqFsPAu6DQYOp8bdzQiEgMlDYnm5+9g+jBIOyj4tZTaMUSqJFVPSfGyfg0avrdvgfPnQI1acUckIjFR0pDiLbwDvloE/R+GRgfHHY2IxEjVU5LYFwvgrb8GbRidBsUdjYjETElDirYxI/h5beND4OR74o5GRMoBJQ0pXNYOmHYhZG2HgU9A9b3jjkhEyoHYkoaZXWFmq8xsm5mtNLPLwvlHm9lH4fz3zeyIPOucZmZfmlmmmS00Mw0qnCyv3gbfvAen3A8N28UdjYiUE7EkDTM7ELgXyAZGA9WB+81sf2A6UAcYBTQGpplZNTNrAkwBNgFXAV2AJ2IIv/L7/CV45/6gT6lDzog7GhEpR+K60sjZ77fAAuA7YBvQnSBRPOjuDwKPAa2BnsBgoCZwp7s/ADwPHGNmbcs29Erup6/g+RHQtBP87o64oxGRciaWpOHunwPXAkcD/wE6A8OB/cNFvg2nGeG0DUHyKKosHzMbbmaLzWzxunXrSjn6SuzX7cGASp4NAydB9dS4IxKRciau6qk04DLgA+A04EPg70Dtgosm2kxRBe7+iLunu3t6WlpayYKtSubfDN8ugVMnBD3YiogUEFf1VE+gOTDD3WcCMwjaMT4Ly1uE0+bhdAWwMkGZlNSymfDeP6DbSOhwStzRiEg5Fdcd4TkJ4BwzWwOcHT7/L7AWGGlmPwNDgVXAQmAZcBdwjZk1BvoDi9x9eRnGXTn9uAJmXgrNu8AJt8UdjYiUY3G1aSwGriRo2J4QTi919w+BgcBm4G8ECWSgu2e5+xqCxvD6wDhgKTCkzIOvbHZkwtQhYCkw4HHYq0bcEYlIORZb31PuPh4YX8j8N4FDi1hnBkFVlpSWl6+HNR/C4Cmw7wFxRyMi5ZzuCK/KPp4Gix+D3/wJDjop7mhEpAJQ0qiqfvgCZl8O+3eD42+OOxoRqSCUNKqiHb/Ac+dDtRpBO0a16nFHJCIVhMbTqIpevArWfgpnT4d6zYtfXkQkpCuNqubDKbD0KTjmz3Bg77ijEZEKJlLSMLO+ZnafmXUws3PMrFOyA5MkWPsfmDMKDugBPa+LOxoRqYCKTRpmdgUwm6DbjybA6YBG5Klotm+BqecH43sPeAyqqWZSRHZflCuNK4CpeZ4vAI4ofFEpl9xhzmhY9zmc8SjUaRJ3RCJSQUVJGvsSdCiYYx+gWnLCkaRY+hR8NAV6XgttesYdjYhUYFHqKN4DRoZ//xnoAbydtIikdH33SfBrqTY94bdXxR2NiFRwUa40/gT8QtAV+YnAGoIqKynvtv0ctGOk1ofTH4UUXSCKSMkUe6Xh7v8xs/bAQeGsz909K7lhSYm5B3d8/7gCzp8DtTWuiIiUXLFJw8zqEvQm25qwLcPM3N0vT25oUiKLH4NPpgddhLQ6Ou5oRKSSiNKmMRs4psA8B5Q0yqvVH8C866DdCXD0qLijEZFKJErSOAJ4GpgEqFqqvMvcGLRj1EqD/g9Dim76F5HSEyVpPEwwxOpKYGNyw5EScYeZl8DGDBjyItTaL+6IRKSSifI19AtgAPAlsC58rE1mULKH3nsYPpsNvW+Flt3ijkZEKqEoVxp3EQy/+gmwI7nhyB7LWAKv3AgHnQxHXRp3NCJSSUVJGl8Aj7v7P5IdjOyhrT8G43zXbQqnPQhmcUckIpVUlKSxFrjDzLqzs01DP7ktL9zhhT/Cz2tg6Muw975xRyQilViUpHFyOD03zzz95La8eOcB+O9LcNJYaN4l7mhEpJKLkjR6JT0K2TNfvwsLboUOp8KRw+OORkSqgCKThpk1ADYBH5ddOBLZlvUw9QKo3xJOeUDtGCJSJhJdaawDBgOTCynzYtaVZMrOhueHw9b1MGw+pNaLOyIRqSISnfjfJEgcbxEkCSkvFo2HLxdA3/HQVCPvikjZKTJpuHsvADNbDvzg7lvLLCop2qpF8PrtcMgASL8w7mhEpIqJckf4SqBvzhMzG2hm25IXkhRp81qYdiE0aAO/v0/tGCJS5hI1hB8GHE4w+FJPM9s7LDo5nCdlKTsLpg8LOiQ893moWSfuiESkCkp0pdGfoGdbB0YAj4ePM4EPSrpjM6tvZk+a2QYz22xmb4bzjzazj8xsm5m9b2ZH5FnnNDP70swyzWyhmbUuaRwVxhtjYeUbcPI4aNwx7mhEpIpK1BD+CrAFGAv8kyBROPATMKsU9j0ROBW4D/gM+I2ZpQLTCYaXHQXcAEwzswOBNGAKsAy4CrgDeAL4bSnEUr4tfx3euBs6/QE6nxN3NCJShSVqCP8X8C8z+zewzN3XldZOzawNwZXMP4HrgCx3f9TM+gONgavd/UEzawLcBPQEDgNqAne6+1Qz6wqca2Zt3X15acVW7mxaAzMugrSDoO84tWOISKyijBH+RhL22yGcdiW4mskys78B34fzvw2nGeG0DcFws0WV5UsaZjYcGA7QsmXLUg28TGX9CtOHwvYtwTjfNWrFHZGIVHFxDetWM5zWAs4C3gauZtckluhrdZFl7v6Iu6e7e3paWlqJAo3Vwjvgq7eh333Q6OC4oxERie2u7pXh9C13n2FmacBx7EwELcJp83C6AqidoKzy+WI+vPVXOOI86HRW3NGIiAARkoaZFdbQvAH4zN33dFCmpQR9Wh1vZhcBFxCMPz4XGA2MNLOfgaHAKmAhQQP4XcA1ZtaYoE1kUaVsz9iYATOGQ+NDgt5rRUTKiSjVUwuB1ws8lgJfmtke9WHh7k7Qr9Vy4AGgAXCeu38CDCQYKfBvBGN5DHT3LHdfE65THxgXxjBkT/ZfrmXtCDoizNoOA5+A6nsXv46ISBmJUj31AnACMJOg+ugUYBFBI/ZY4Hd7smN3/xQ4qpD5bwKHFrHODGDGnuyvwnh1DGT8PxgwERq2izsaEZF8olxpNAWudfdz3P1sgp/I1iIYhKlrMoOrcv7zYjCoUtdhcMgZcUcjIrKLKFcaBwMDzWxZ+HwA0BFYA9RIVmBVzk9fwQsjoOnh8Ls74o5GRKRQUZLGRIK7sxeEzw0YD3QC/p2kuKqWX7fD1CHB/fYDJ8FeNYtZQUQkHlFu7rvSzN4guCsb4HV3nx3+fW+yAqtS5t8Eq9+Hs56GBlWnOy0RqXii3qfxIrAEqAZgZi3d/eukRVWVLJsJ7z0E3f8I7X8fdzQiIglFuU/jT8CdQGqe2RrutTT8uAJmXgrNu0DvMXFHIyJSrCgn/luBTILhX39NajRVyY5MeO58sJSwHUO/KRCR8i9K0vgaeNjd/5HsYKqUl6+D7z6Cwc9C/QrcqaKIVClRksYy4CYza0YwlgYEN3WrEXxPfTwNFk+Eoy+Hg06MOxoRkciiJI1B4fSGPPMc/XJqz/zwBcy+HPbvDsfdFHc0IiK7JUrSuJAgSUhJbd8atGPsVTPoJqRa9bgjEhHZLVHu05hUBnFUDS9dDWuXwTnToF7z4pcXESlniux7ysw2mVn/cFrwsbEsg6wUPpgMS5+CY66Edr3jjkZEZI8kutJYD+wAfkTVUyWz9jOYOxpaHQM9r4s7GhGRPVZk0nD3nP4s5pRRLJXTts1BO0aN2nDGo1BN90SKSMUV5Y7wVOAMoBVhNyIEP7n93yTGVTm4w9wr4Yf/wnkzoU6TuCMSESmRKF97ZwK92Tl+NwTVVUoaxVn6FHw0BXpeD22OjTsaEZESi5I0ugEvA0+gbkSi++4TePEqaNMLfvvnuKMRESkVUZLGHCDD3Z9NdjCVRuYmeO482HtfOP3/IKVa8euIiFQAUZLGkcBgMzuH4JdUELRpdEpeWBWYe3DH90+r4PzZUDst7ohEREpNlKTRLpw2Cx+SyOLH4NMZcPwt0OrouKMRESlVUe4IL/IGQClg9VKYdx0c2AeOviLuaERESl2RScPMTgfeBboXUuzu/nzSoqqIftkQjPNdqxH0fxhSlGtFpPJJdKUxFRgMTCH/HeEWPlfrbg53mHkJbMyAC16CfRrEHZGISFIkShq3AZ8CGoe0OO89BP+ZA31uh/2PjDsaEZGkSdSNSE6y+LSMYqmYMhbDKzfBQX3hqEvijkZEJKmidCPSlGCc8EOB1HC2u3uXJMZVMWz9MWjHqNsUTpsAZsWuIiJSkUVprX0UGEpwZ3hH4HCgdaIVojKzVDP73MzczP4ezmtvZu+Y2bawrE+e5Y82s4/CsvfN7IjSiGOPZGfDCyPh5+9g4KTgRj4RkUouStL4DXBn+Hdf4CFgQint/2agRYF5k4GDgdEEXbNPNbN6YceJ04E6wCigMTDNzOJpkP/XA/DfefC7O6C5LrpEpGqIkjRqACsJfjV1OPAzcHlJd2xmhxGc/G/JM68z0AmY7O4TgPFAXWAAcBJBonjQ3R8EHiO44ulZ0lh229fvwoIx0OE0OPKiMt+9iEhcotwRvgpoCHwE3B3O+09JdmpmKQTVXhOAxXmKcqq9vg2nGeG0DVAvQdmrJYlnt2z5AaZeAPVbwin3qx1DRKqUKEnjTGA78CJwI8E9GreXcL8XEIzPMYyggR2CpFC9wHKJzshFlpnZcGA4QMuWLfc4yF1kZ8OM4bB1PQybD6n1il9HRKQSSZg0wvaCx4F73X0yMKiU9rs/kAZ8mGfeOezs2yqnnaN5OF3Bzs4SCyvLx90fAR4BSE9PL72haheNh+WvQr97oan6axSRqidh0nD3LDNzoBS/rgPwHPBJ+HdHgp/0ziO4kpkIDDKzT4GRBG0o04FMYC0w0sx+JvhF1ypgYSnHVriVb8Hrt8OhA6HLBWWySxGR8iZK9dQPwBgz6wqsDue5u+9xY7i7LwOWAZjZD+Hs5e6+xMz+QNDeMR74CjjT3TeEyw4kaAf5G8FNhxe5e9aexhHZ5rUwfSg0aAv97lM7hohUWeaeuPbGzLILme3uXiH6nkpPT/fFixcXv2BRsrPgqdPgm3/DRa9C446lFpuISHllZkvcPb3g/ES93K4ALgN6JTOwcu+NsbDyTTh1ghKGiFR5iaqnWgG13H1uGcVS/ix/Dd64Gw4/GzqfE3c0IiKxK65N49jwTuxduPuTSYin/Ni0BqZfBGkHw8nj4o5GRKRcKC5pjAgfeeWMp1G5k8b8m2DHL3DmE1Bjn7ijEREpF4pLGs8AH5RBHOXPSWOh87mQdlDckYiIlBvFJY3Z7v5cmURS3uzTANocG3cUIiLlSqIOC78CtpRVICIiUv4lGrmvVMbMEBGRyiNK1+giIiKAkoaIiOwGJQ0REYlMSUNERCJT0hARkciUNEREJDIlDRERiUxJQ0REIlPSEBGRyJQ0REQkMiUNERGJTElDREQiU9IQEZHIlDRERCQyJQ0REYlMSUNERCJT0hARkciUNEREJDIlDRERiUxJQ0REIoslaZjZgWb2upmtN7OfzWy+mbUNy04zsy/NLNPMFppZ6zzrXWxmGWb2i5nNNLP94ohfRKSqiutKo3m471uAx4HewKNm1gSYAmwCrgK6AE8AmFln4CHgs3C9vsC9ZR65iEgVtldM+33H3Y/NeWJmZwMdgcFATeBOd59qZl2Bc8OrkCHh4te7+7/NrB8w2MyGu3tmGccvIlIlxXKl4e7bc/42s3SgAfAmkFMV9W04zQinbYoo2wvYv+D2zWy4mS02s8Xr1q0r5ehFRKquWBvCzexgYBawCrissEUSrV5Ugbs/4u7p7p6elpZWsiBFRCRXbEnDzDoAC4HtwHHuvgZYGRa3CKfNw+mKIsp+Bb5JerAiIgLE9+up/YHXgYYEjdvdzGwQQSP4duAaM7sM6A8scvflwJPh6reb2dXAb4Apas8QESk7cTWEtwUahX/fmTPT3c3MBgP3AOOA94ALwrIlZnYJcANwDPASMKosgxYRqerM3eOOIanS09N98eLFcYchIlKhmNkSd08vOF93hIuISGRKGiIiEpmShoiIRKakISIikSlpiIhIZEoaIiISmZKGiIhEpqQhIiKRKWmIiEhkShoiIhKZkoaIiESmpCEiIpEpaYiISGRKGiIiEpmShoiIRKakISIikSlpiIhIZEoaIiISmZKGiIhEpqQhIiKRKWmIiEhkShoiIhKZkoaIiESmpCEiIpEpaYiISGRKGiIiEtlecQcgIlJVuTvZDtnuZLvjuX8HU8/eWZbtO5d3wmWy866Tf5lsd1rsuzd1UquXasxKGiIx8sJOFAVOAtnZhZ8QcpbNKqY82z1cJnH5rnHs/Lu48txtZxf2OhIsn2cexbwPwfaLXt93eV2Jl9n1/cizfPbO5XNP0AXXz06wfhExFdx/sk26oCs9D2pUqtuscEnDzI4G/gEcBHwKDHP39+ONavcV9uEt6h+64DTSOuT/x8//j5r3ZJR/u06eD3ieDygU8eHIJv86BZbxIj5Q7ru/zs7X7GQVcyLJ8sJfR8HtFTxBZEcsz/k7q5iTR+En27I9cZRXKQYpZpiBmeU+z5mXkmde/vJw+ZRdlzfIv35KgvUNUlJSitxfMC9iTCmJX4MVt35uTHnL8yyfsnN5o5BlinidHZrVLfXjVqGShpmlAtOBX4BRwA3ANDM70N2zSnNf97/6BTM/+BanwIk5u8CJueDJPNt3XaeQE78UruAHLaXAyQCDaimW+8Es7kRSreAHuMCHK295tRSjeortUl74ySH/CSLRySP/B7/wE0c1s8TlKYlPMsWVp4Tb3/WEtHPZasWUp+R57wuWk+e9TDHDUgq+jl23JxVThUoawElAY+Bqd3/QzJoANwE9gVdLc0eN6tTk4CZ1i/wQmxWe2RN9o9ijdcj/LSPfOhR+Isz5JlLYyS53nYIn5pSgrLBvS0WdQPJ9wytkmSITgE4kIhVWRUsarcPpt+E0I5y2IU/SMLPhwHCAli1b7tGOBh3ZkkFH7tm6IiKVVUX/yW2hX03d/RF3T3f39LS0tLKOSUSk0qpoSWNlOG0RTpuH0xUxxCIiUuVUtOqpl4C1wEgz+xkYCqwCFsYYk4hIlVGhrjTcPRMYCGwG/kaQQAaW9i+nRESkcBXtSgN3fxM4NO44RESqogp1pSEiIvFS0hARkciUNEREJDJzr9x9WpjZOuCrPVy9IfBDKYYjpUPHpfzRMSmfSnJcDnD3XW50q/RJoyTMbLG7p8cdh+Sn41L+6JiUT8k4LqqeEhGRyJQ0REQkMiWNxB6JOwAplI5L+aNjUj6V+nFRm4aIiESmKw0REYlMSUNERCKrsknDzFaZmed5fBDOP9rMPjKzbWb2vpkdEc7vGS739/D5UWa2xcy+NjON1rSHzOx+M/s+fG/n5Jnf3szeCY/D52bWJ0+ZjlESJTgmCwt8ZjbkKSv0eJlZq7zbMbMDw21vMLPDy/q1VVTh+/a6ma03s5/NbL6ZtQ3LTjOzL80sMzxGrfOsd7GZZZjZL2Y208z2C+ffGh6XAeHzP4XPXzazGoliqbJJI/QmMDh8XJNnDPI6BGOQNyYYg7xa3pXM7BBgLrAFOMHdvy7TqCufKYXMmwwcDIwGdgBTzayejlGZKeyYAHzGzs/MhXnmF3q88q5oZs2B+QTHrp+7f1DKMVdmzQnO17cAjwO9gUfDIa+nAJuAq4AuwBMAZtYZeIjgmN0C9AXuLbhhMzsHuA/4F3C6u29PGIm7V8kHwTgck4A6eeb1Bxy4Knx+W/j8eIJxyB2YA6wGNgJHxP06KsMDaJXz3obPO4fPJ4TPLwyfD9UxiueYhPMWho86BZZNdLxytvMO8CmwHTgp7tdX0R5AjQLP1xMMDTEqfH8HhvOfDJ+3JRg+woGuYdmbBAk9Fbg1LHs8nPcRsG+UWKr6lcZ5wCYzW2tmQ0k8BnmOvkBToL+7v182YVY5iY6DjlG8fkvwmdlkZjeE86Ick6OADsDF7v5S8sOsXDzPt38zSwcaECSB3f2s7AXsn2fTQwgS0O/c/acosVTlpPF/wJnAuQTffh5m1zHHCxuDPDucDk5eaFJAoWPBJyjTMUqO6cDZBAOhfQP8xcyOKWS5RMfkTDOrnqT4Kj0zOxiYRVBTcllhiyRavZB52UAjguquSCrcIEylxd1vz/k7rPsbzc4snWgM8icJ6m6HmdkP7n5dsmOtghKNBf9jgrIcOkZJ4O4P5PxtZk2B+wmuHv5fODvRMXkFyAROAyaZ2Tke1plINGbWAXiN4H08zt3XmFmiz0restVh2a8ECT/HzcAVwEQz+9Hd5xYbSNx1dTHVDx4GzAYuAf4ErAO2As2A78M3eyTBZd1KoBo768v/TnBp+Gn4fHTcr6ciPwiqkq4J38sPgWHAgeHfP4bH6BOChr76BPWxOkZlf0w6AW+EJ5iLgeVAFmGbUYLj1Yqd7Uw1CdpEHLg/7tdZkR4EVUrfE5z0rwUGhY+mwDZgCcGVx8/AW+E6XcL3ej5wdbjuU2HZrWHZACA9XG8r0KPYWOJ+M2I6AE2BFwm6DN4KLCao04OgzvZjgiqrpUB6OD/3hBQ+b0HQ5Xo2cF7cr6miPvKcRPI+hgAdCX7NsQ34L3BinnV0jMr+mIwApgHfAb+ECfnsPOsUerzY9UcOdcNj5sDNcb/WivLI87+d7xGWnU6QxLcRtHO0zbPeHwm+WGUSfFFuGM7PTRrh897h+j8BhyWKRd2IiIhIZFW5IVxERHaTkoaIiESmpCEiIpEpaYiISGRKGiIiEpmShkgBeXpm9bDn0G/M7J95ew9NsO4+YQ+iQ0oxnny994rEST+5FSnAzFoR3DC4lOCu514E/ZR9B3Ry97UJ1m1IcLPoG+7es5TiaQQcB/zX1ZeWxExXGiJFW+3uk9z9fIK+ypoAlwKY2VQz+ym8EllmZv3DdRaH02PDq4Nbzax3nvEOfjCzKWZWp+DOzKyRmb1qZpvDDgHfM7M0gq46JhN2RV5gTAs3s4Xh/KPM7F/h+v81M/W9JaVOSUMkmpyeWdPD6b8JumbI6dfqyXCsj+vD5znjTkwDNgMPEnRZMxk4K/y7oLMJrij+ClwJfEDQPUpBOeNZzMqJxcwaEHTVUR+4naBDu6c10JGUtirbYaHIbsrpIdTDAZ86EvT9k3eUs1YEHfMBrHX3KQBm1ougO4e2eZY9tJB9fBFOjwcWAc+6+3dhz6a53H2KmR0PnESQzK4FTiTob6sBcEeexY8jSD4ipUJXGiLR/C6cLgFOIGjjeJPgZJ3TM2gqQX8+Bd1JML7BUIKrjJxl83H3OUB3YB7QA3jVzHbpsjrs7XQ6wdXMWe6elaf4yTC+nMesguuLlISShkjRmpnZEDN7HLiIoCF8Qp7yWgQ98h6dZ94mgg4S25nZ2WZ2QDjfgIYEY1EUKhyvuR9B19Wf5sRQYJnaBEmqDvAU0NfMjiPoLPBHgiR2MHAIwRVIc0RKkZKGSNE6EwzO1Rt4BjjK3b8n6Gp6CnA4QRXVyzkruPsO4B6CtoWngWMI2jm+IWj/+CDB/rYCZxCM63wm8CxBm0heDQmqwVLC/Uwm6C32R4KE8yVwF3BDuL1Vu/uiRRLRT25FRCQyXWmIiEhkShoiIhKZkoaIiESmpCEiIpEpaYiISGRKGiIiEpmShoiIRPb/AaY9oUKv0NsXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.plot(x_axis, time[0])\n",
    "#plt.plot(x_axis[:2], time[1])\n",
    "plt.plot(x_axis[:2], time[2])\n",
    "plt.legend((\"Procrustes\", \"GCN-Align\"))\n",
    "plt.xlabel(\"Data size\")\n",
    "plt.ylabel(\"Training time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.plot(x_axis, time[0])\n",
    "#plt.plot(x_axis[:2], time[1])\n",
    "plt.plot(x_axis[:2], time[2])\n",
    "plt.legend((\"Procrustes\", \"GCN-Align\"))\n",
    "plt.xlabel(\"Data size\")\n",
    "plt.ylabel(\"Training time\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unikge",
   "language": "python",
   "name": "unikge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
