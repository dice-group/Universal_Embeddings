{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "thrown-beverage",
   "metadata": {},
   "source": [
    "# Dbpedia and Caligraph---Reading files and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "direct-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import time, gc\n",
    "gc.enable()\n",
    "base_path = !pwd\n",
    "base_path = base_path[0]\n",
    "list_files = [base_path+\"/data/caligraph/\"+f for f in os.listdir(base_path+\"/data/caligraph/\") if os.path.isfile(base_path+\"/data/caligraph/\"+f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "floral-municipality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-provenance.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-transitive-types.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-to-dbpedia-mappings.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-labels.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-ontology.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-relations.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-types.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-class-to-dbpedia.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-provenance.nt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rocky-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(list_files[2]) as file:\n",
    "    caligraph2dbpedia_mappings = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sensitive-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(mapping):\n",
    "    x,_,y,_ = mapping.split()\n",
    "    return x.strip('<>'), y.strip('<>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "urban-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "caligraph2dbpedia_mappings = dict(map(lambda x: get_map(x), caligraph2dbpedia_mappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stylish-connecticut",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://caligraph.org/resource/Cameroon_sheep',\n",
       " 'http://dbpedia.org/resource/Cameroon_sheep')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(caligraph2dbpedia_mappings.items())[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "green-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbpedia2caligraph_mappings = {value: key for key,value in caligraph2dbpedia_mappings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "final-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "modern-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_caligraph = KeyedVectors.load(\"./Caligraph_Dbpedia/caligraph/caligraph-v211_500_4_sg_200_vectors.kv\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "worse-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_dbpedia = KeyedVectors.load(\"./Caligraph_Dbpedia/dbpedia/dbpedia.kv\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-census",
   "metadata": {},
   "source": [
    "### There are mismatches between entity IRIs in 'caligraph2dbpedia_mappings' and those in the computed embeddings, see below. We will write a function that fixes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "velvet-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_namespace(iri, kg='dbpedia'):\n",
    "    if kg == 'dbpedia':\n",
    "        if 'owl#' in iri:\n",
    "            return iri\n",
    "        iri = iri.replace('dbr:', 'http://dbpedia.org/resource/')\n",
    "        return 'http://dbpedia.org/resource/' + iri.split('/')[-1]\n",
    "    elif kg == 'caligraph':\n",
    "        if 'owl#' in iri or 'ontology' in iri:\n",
    "            return iri\n",
    "        return 'http://caligraph.org/resource/' + iri.split('/')[-1]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "according-customer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emb_keys_db = set(map(lambda t: repair_namespace(t), word_vectors_dbpedia.key_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "helpful-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emb_keys_cal = set(map(lambda t: repair_namespace(t, 'caligraph'), word_vectors_caligraph.key_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "figured-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-walnut",
   "metadata": {},
   "source": [
    "### Creating entity to vector maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "middle-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2vec_db = {}\n",
    "entity2vec_cal = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "empirical-newsletter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15048578/15048578 [02:47<00:00, 89993.95it/s] \n"
     ]
    }
   ],
   "source": [
    "for ent in tqdm(word_vectors_dbpedia.key_to_index):\n",
    "    try:\n",
    "        entity2vec_db[repair_namespace(ent)] = np.array(word_vectors_dbpedia.get_vector(ent)).astype(np.float16)\n",
    "    except KeyError:\n",
    "        if repair_namespace(ent) in entity2vec_db:\n",
    "            entity2vec_db.pop(repair_namespace(ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "extra-sender",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16429696/16429696 [03:04<00:00, 88928.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for ent in tqdm(word_vectors_caligraph.key_to_index):\n",
    "    try:\n",
    "        entity2vec_cal[repair_namespace(ent, 'caligraph')] = np.array(word_vectors_caligraph.get_vector(ent)).astype(np.float16)\n",
    "    except KeyError:\n",
    "        if repair_namespace(ent) in entity2vec_cal:\n",
    "            entity2vec_cal.pop(repair_namespace(ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "directed-relations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del word_vectors_dbpedia, word_vectors_caligraph\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "younger-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_aligned_entity_dict = dict()\n",
    "#\n",
    "#for key, value in tqdm(caligraph2dbpedia_mappings.items()):\n",
    "#    if key in entity2vec_cal and value in entity2vec_db:\n",
    "#        new_aligned_entity_dict.update({key: value})\n",
    "#\n",
    "#\n",
    "#print('There are ', len(new_aligned_entity_dict), ' aligned entities with available embeddings')\n",
    "\n",
    "with open('Caligraph_Dbpedia/caligraph2dbpediaalignment.json', 'r') as file:\n",
    "    new_aligned_entity_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-journalism",
   "metadata": {},
   "source": [
    "# Computing aligned KG embeddings with a simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "alternative-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "social-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignmentModel(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.R = torch.nn.Parameter(\n",
    "                         torch.tensor(np.random.uniform(-1, 1, (emb_dim, emb_dim)),\n",
    "                         dtype=torch.float, requires_grad=True))\n",
    "        \n",
    "    def forward(self, s):\n",
    "        return torch.mm(s, self.R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hungry-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(S, T, batch_size=128):\n",
    "    for i in range(0, S.shape[0]-batch_size+1, batch_size):\n",
    "        yield S[i:i+batch_size], T[i:i+batch_size]\n",
    "\n",
    "\n",
    "def train(model, lr, epochs, S, T, batch_size=128):\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    Loss = nn.MSELoss()\n",
    "    for epoch in range(epochs):\n",
    "        loss_epoch = 0\n",
    "        for S_batch, T_batch in tqdm(get_batch(S, T, batch_size=batch_size), total=S.shape[0]//batch_size):\n",
    "            proj = model(S_batch)\n",
    "            loss = Loss(proj, T_batch)\n",
    "            loss_epoch += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Loss epoch {epoch} : {loss_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-senegal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cordless-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Caligraph_Dbpedia/caligraph2dbpediaalignment.json', 'w') as file:\n",
    "#    json.dump(new_aligned_entity_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-automation",
   "metadata": {},
   "source": [
    "# Computing aligned KG embeddings using Orthogonal Procrustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "governing-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import procrustes\n",
    "from scipy.linalg import orthogonal_procrustes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-cologne",
   "metadata": {},
   "source": [
    "## Get the embedding matrices of aligned an non-aligned entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "german-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_and_target_matrices(alignment_dict, entity2vec1, entity2vec2, given_test_set=None, emb_dim=200, test_size=0.1):\n",
    "    \"\"\"This function takes the dictionary of aligned entities between two KGs and their corresponding embeddings (as entity to vector dictionaries)\n",
    "    and returns S, T, S_eval, T_eval, and R defined as follows:\n",
    "    \n",
    "    -- S: Normalized and scaled large subset of the source embeddings, i.e. the matrix of aligned entity embeddings in the first knowledge graph\n",
    "    \n",
    "    -- T: Normalized and scaled large subset of the matrix of aligned entity embeddings in the second knowledge graph\n",
    "    \n",
    "    -- S_eval and T_eval are portions of S and T sampled for evaluation if test_size > 0\n",
    "    \n",
    "    -- R: The rotation matrix that most closely maps S to T, i.e. ||A@S-T|| is minimized\n",
    "    \n",
    "    The mean and standard deviation of S, T are also returned\n",
    "    \"\"\"\n",
    "    if test_size > 0:\n",
    "        if given_test_set is None:\n",
    "            train_ents, eval_ents = train_test_split(list(alignment_dict.keys()), test_size=test_size, random_state=42)\n",
    "        else:\n",
    "            eval_ents = given_test_set\n",
    "            train_ents = list(set(alignment_dict.keys())-set(eval_ents))\n",
    "    else:\n",
    "        train_ents = alignment_dict.keys()\n",
    "        \n",
    "    S = np.empty((len(train_ents), emb_dim))\n",
    "    T = np.empty((len(train_ents), emb_dim))\n",
    "    if test_size > 0:\n",
    "        S_eval = np.empty((len(eval_ents), emb_dim))\n",
    "        T_eval = np.empty((len(eval_ents), emb_dim))\n",
    "\n",
    "    for i, key in tqdm(enumerate(train_ents), total=len(train_ents), desc='Computing S and T'):\n",
    "        S[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "        T[i] = entity2vec2[alignment_dict[key]] if isinstance(entity2vec2, dict) else entity2vec2.loc[alignment_dict[key]].values\n",
    "        \n",
    "    if test_size > 0:\n",
    "        for i, key in tqdm(enumerate(eval_ents), total=len(eval_ents), desc='Computing S_eval and T_eval'):\n",
    "            S_eval[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "            T_eval[i] = entity2vec2[alignment_dict[key]] if isinstance(entity2vec2, dict) else entity2vec2.loc[alignment_dict[key]].values\n",
    "        \n",
    "    print('\\nNow computing R...')\n",
    "    # Center and scale data\n",
    "    mean_S = S.mean(axis=0)\n",
    "    mean_T = T.mean(axis=0)\n",
    "    scale_S = np.sqrt(((S-mean_S)**2).sum()/S.shape[0]) # scale, see https://en.wikipedia.org/wiki/Procrustes_analysis\n",
    "    scale_T = np.sqrt(((T-mean_T)**2).sum()/T.shape[0])\n",
    "    print('Scale S: ', scale_S)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    R, loss = orthogonal_procrustes((S-mean_S)/scale_S, (T-mean_T)/scale_T, check_finite=True)\n",
    "    print('\\nCompleted after '+str(time.time()-t0)+' seconds')\n",
    "    print('Alignment loss: ', loss)\n",
    "    if test_size > 0:\n",
    "        return scale_S, scale_T, mean_S, mean_T, (S-mean_S)/scale_S, (T-mean_T)/scale_T, (S_eval-mean_S)/scale_S, (T_eval-mean_T)/scale_T, R\n",
    "        #return scale_S, scale_T, mean_S, mean_T, S, T, S_eval, T_eval, R\n",
    "    else:\n",
    "        return scale_S, scale_T, mean_S, mean_T, (S-mean_S)/scale_S, (T-mean_T)/scale_T, R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "coordinated-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_aligned_entity_embedding_matrices(alignment_dict, entity2vec1, entity2vec2, scale_S, scale_T, mean_S, mean_T, emb_dim=200):\n",
    "    \"\"\"\n",
    "    Inputs the dictionary of aligned entities between two KGs and their corresponding embeddings, and returns the normalized embedding matrices of \n",
    "    \n",
    "    non-aligned entities\n",
    "    \"\"\"\n",
    "    A_neg_S = np.empty((len(entity2vec1)-len(alignment_dict), emb_dim))\n",
    "    keys = sorted(set(entity2vec1.keys() if isinstance(entity2vec1, dict) else entity2vec1.index)-set(alignment_dict.keys()))\n",
    "    for i, key in tqdm(enumerate(keys), total=A_neg_S.shape[0], desc='Computing A_neg_S...'):\n",
    "        A_neg_S[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "    \n",
    "    B_neg_T = np.empty((len(entity2vec2)-len(alignment_dict), emb_dim))\n",
    "    keys = sorted(set(entity2vec2.keys() if isinstance(entity2vec2, dict) else entity2vec2.index)-set(alignment_dict.values()))\n",
    "    for i, key in tqdm(enumerate(keys), total=B_neg_T.shape[0], desc='Computing B_neg_T...'):\n",
    "        B_neg_T[i] = entity2vec2[key] if isinstance(entity2vec2, dict) else entity2vec2.loc[key].values\n",
    "        \n",
    "    return (A_neg_S-mean_S)/scale_S, (B_neg_T-mean_T)/scale_T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "civilian-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "imposed-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_alignment_knn(S_eval, T_eval, R, hit_values = [1, 3, 10]):\n",
    "    \"\"\"The function takes the evaluation sets, i.e. correct alignments that were left out, and returns the hits@ and MRR results w.r.t. correct alignments\n",
    "    \n",
    "    \"\"\"\n",
    "    print('#'*50)\n",
    "    print('Evaluation started...')\n",
    "    print('#'*50)\n",
    "    model = NearestNeighbors(n_neighbors=S_eval.shape[0], n_jobs=-1)\n",
    "    print('Fitting...')\n",
    "    model.fit(T_eval)\n",
    "    print('Predicting...')\n",
    "    preds = model.kneighbors((S_eval@R+T_eval)/2, n_neighbors=S_eval.shape[0], return_distance=False)\n",
    "    Hits = np.zeros(len(hit_values))\n",
    "    MRR = 0.0\n",
    "    for i in tqdm(range(S_eval.shape[0]), total=S_eval.shape[0]):\n",
    "        pred_idx = (preds[i]==i).nonzero()[0][0] # if i in preds[i] else S_eval.shape[0]\n",
    "        MRR += (1./(pred_idx+1))\n",
    "        for j in range(len(Hits)):\n",
    "            if pred_idx < hit_values[j]:\n",
    "                Hits[j] += 1.0/S_eval.shape[0]\n",
    "    MRR = MRR/S_eval.shape[0]\n",
    "    print()\n",
    "    print(', '.join([f'Hits@{hit_values[it]}: {Hits[it]}' for it in range(len(Hits))]+[f'MRR: {MRR}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sublime-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_alignment(S_eval, T_eval, R, num_candidates=10):\n",
    "    \"\"\"The function takes the evaluation sets, i.e. correct alignments that were left out, and returns the accuracy computed as the proportion\n",
    "    of correct alignment predictions among num_candidates candidates\n",
    "    \n",
    "    \"\"\"\n",
    "    print('#'*50)\n",
    "    print('Evaluation started...')\n",
    "    print('#'*50)\n",
    "    acc = 0\n",
    "    ids = list(range(S_eval.shape[0]))\n",
    "    for i in tqdm(range(S_eval.shape[0])):\n",
    "        s_i = S_eval[i][None, :]@R\n",
    "        rand_ids = list(set(random.sample(ids, k=num_candidates))-{i})\n",
    "        candidates = np.concatenate([T_eval[i][None, :], T_eval[rand_ids[:num_candidates-1]]], axis=0)\n",
    "        acc += ((candidates-s_i)**2).sum(1).squeeze().argmin() == 1\n",
    "    return acc / S_eval.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-partner",
   "metadata": {},
   "source": [
    "## Evaluate, compute and store universal embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "theoretical-heart",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 3370708/3370708 [00:33<00:00, 99186.78it/s] \n",
      "Computing S_eval and T_eval: 100%|██████████| 374524/374524 [00:03<00:00, 100404.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  3.398963744580538\n",
      "\n",
      "Completed after 18.295594930648804 seconds\n",
      "Alignment loss:  684426.5036357479\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _, _, _, S_eval, T_eval, R = get_source_and_target_matrices(new_aligned_entity_dict,\\\n",
    "                                                                                           entity2vec_cal, entity2vec_db, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-guatemala",
   "metadata": {},
   "source": [
    "### Evaluation on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting...\n",
      "Predicting...\n"
     ]
    }
   ],
   "source": [
    "#evaluate_alignment_knn(S_eval.astype(np.float16), T_eval.astype(np.float16), R.astype(np.float16), hit_values=[1, 3, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "secondary-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_merged_entities = sorted(set(entity2vec_cal.keys())-set(new_aligned_entity_dict.keys())) +\\\n",
    "#sorted(set(entity2vec_db.keys())-set(new_aligned_entity_dict.values())) + \\\n",
    "#list(new_aligned_entity_dict.keys())\n",
    "#with open('Caligraph_Dbpedia/list_merged_entities_cal_db.txt', 'w') as file:\n",
    "#    file.write(','.join(list_merged_entities))\n",
    "#del list_merged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "comparative-pierce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 3745232/3745232 [00:38<00:00, 97640.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  3.399197955650588\n",
      "\n",
      "Completed after 21.183332681655884 seconds\n",
      "Alignment loss:  760397.9543931824\n"
     ]
    }
   ],
   "source": [
    "scale_S, scale_T, mean_S, mean_T, S, T, R = get_source_and_target_matrices(new_aligned_entity_dict,\\\n",
    "                                                                           entity2vec_cal, entity2vec_db, test_size=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-stranger",
   "metadata": {},
   "source": [
    "### Simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "contemporary-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AlignmentModel(200)\n",
    "#lr = 0.01\n",
    "#epochs = 100\n",
    "#batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "worse-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(model, lr, epochs, torch.Tensor(S), torch.Tensor(T), batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-russell",
   "metadata": {},
   "source": [
    "### Evaluation on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_alignment_knn(S, T, R, hit_values=[1, 3, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "banner-climb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing A_neg_S...: 100%|██████████| 12670001/12670001 [00:47<00:00, 264532.78it/s]\n",
      "Computing B_neg_T...: 100%|██████████| 6280733/6280733 [00:24<00:00, 256525.47it/s]\n"
     ]
    }
   ],
   "source": [
    "A_neg_S, B_neg_T = get_non_aligned_entity_embedding_matrices(new_aligned_entity_dict, entity2vec_cal, \\\n",
    "                                                             entity2vec_db, scale_S, scale_T, mean_S, mean_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "painful-latvia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del entity2vec_cal, entity2vec_db\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "naughty-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute every s_i as (s_i@R+t_i)/2\n",
    "S = (S@R + T)/2\n",
    "del T\n",
    "gc.collect()\n",
    "Universal_Emb = np.concatenate([A_neg_S@R, B_neg_T, S], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "numeric-little",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22695966, 200)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Universal_Emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Caligraph_Dbpedia/Universal_Emb.npy', Universal_Emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "Universal_Emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "del A_neg_S, B_neg_T, S, T, R, Universal_Emb\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-mentor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-tiger",
   "metadata": {},
   "source": [
    "## Shallom embeddings for Fr-En Dbpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chief-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import procrustes\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import time, gc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "gc.enable()\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "still-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_and_target_matrices(alignment_dict, entity2vec1, entity2vec2, given_test_set=None, emb_dim=200, test_size=0.1):\n",
    "    \"\"\"This function takes the dictionary of aligned entities between two KGs and their corresponding embeddings (as entity to vector dictionaries)\n",
    "    and returns S, T, S_eval, T_eval, and R defined as follows:\n",
    "    \n",
    "    -- S: Normalized and scaled large subset of the source embeddings, i.e. the matrix of aligned entity embeddings in the first knowledge graph\n",
    "    \n",
    "    -- T: Normalized and scaled large subset of the matrix of aligned entity embeddings in the second knowledge graph\n",
    "    \n",
    "    -- S_eval and T_eval are portions of S and T sampled for evaluation if test_size > 0\n",
    "    \n",
    "    -- R: The rotation matrix that most closely maps S to T, i.e. ||A@S-T|| is minimized\n",
    "    \n",
    "    The mean and standard deviation of S, T are also returned\n",
    "    \"\"\"\n",
    "    if test_size > 0:\n",
    "        if given_test_set is None:\n",
    "            train_ents, eval_ents = train_test_split(list(alignment_dict.keys()), test_size=test_size, random_state=42)\n",
    "        else:\n",
    "            eval_ents = given_test_set\n",
    "            train_ents = list(set(alignment_dict.keys())-set(eval_ents))\n",
    "    else:\n",
    "        train_ents = alignment_dict.keys()\n",
    "    \n",
    "    S = np.empty((len(train_ents), emb_dim))\n",
    "    T = np.empty((len(train_ents), emb_dim))\n",
    "    if test_size > 0:\n",
    "        S_eval = np.empty((len(eval_ents), emb_dim))\n",
    "        T_eval = np.empty((len(eval_ents), emb_dim))\n",
    "\n",
    "    for i, key in tqdm(enumerate(train_ents), total=len(train_ents), desc='Computing S and T'):\n",
    "        S[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "        T[i] = entity2vec2[alignment_dict[key]] if isinstance(entity2vec2, dict) else entity2vec2.loc[alignment_dict[key]].values\n",
    "        \n",
    "    if test_size > 0:\n",
    "        for i, key in tqdm(enumerate(eval_ents), total=len(eval_ents), desc='Computing S_eval and T_eval'):\n",
    "            S_eval[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "            T_eval[i] = entity2vec2[alignment_dict[key]] if isinstance(entity2vec2, dict) else entity2vec2.loc[alignment_dict[key]].values\n",
    "        \n",
    "    print('\\nNow computing R...')\n",
    "    # Center and scale data\n",
    "    mean_S = S.mean(axis=0)\n",
    "    mean_T = T.mean(axis=0)\n",
    "    scale_S = np.sqrt(((S-mean_S)**2).sum()/S.shape[0]) # scale, see https://en.wikipedia.org/wiki/Procrustes_analysis\n",
    "    scale_T = np.sqrt(((T-mean_T)**2).sum()/T.shape[0])\n",
    "    print('Scale S: ', scale_S)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    R, loss = orthogonal_procrustes((S-mean_S)/scale_S, (T-mean_T)/scale_T, check_finite=True)\n",
    "    print('\\nCompleted after '+str(time.time()-t0)+' seconds')\n",
    "    print('Alignment loss: ', loss)\n",
    "    \n",
    "    if test_size > 0:\n",
    "        return scale_S, scale_T, mean_S, mean_T, (S-mean_S)/scale_S, (T-mean_T)/scale_T, (S_eval-mean_S)/scale_S, (T_eval-mean_T)/scale_T, R\n",
    "        #return scale_S, scale_T, mean_S, mean_T, S, T, S_eval, T_eval, R\n",
    "    else:\n",
    "        return scale_S, scale_T, mean_S, mean_T, (S-mean_S)/scale_S, (T-mean_T)/scale_T, R\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mediterranean-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_aligned_entity_embedding_matrices(alignment_dict, entity2vec1, entity2vec2, scale_S, scale_T, mean_S, mean_T, emb_dim=200):\n",
    "    \"\"\"\n",
    "    Inputs the dictionary of aligned entities between two KGs and their corresponding embeddings, and returns the normalized embedding matrices of \n",
    "    \n",
    "    non-aligned entities\n",
    "    \"\"\"\n",
    "    A_neg_S = np.empty((len(entity2vec1)-len(alignment_dict), emb_dim))\n",
    "    keys = sorted(set(entity2vec1.keys() if isinstance(entity2vec1, dict) else entity2vec1.index)-set(alignment_dict.keys()))\n",
    "    for i, key in tqdm(enumerate(keys), total=A_neg_S.shape[0], desc='Computing A_neg_S...'):\n",
    "        A_neg_S[i] = entity2vec1[key] if isinstance(entity2vec1, dict) else entity2vec1.loc[key].values\n",
    "    \n",
    "    B_neg_T = np.empty((len(entity2vec2)-len(alignment_dict), emb_dim))\n",
    "    keys = sorted(set(entity2vec2.keys() if isinstance(entity2vec2, dict) else entity2vec2.index)-set(alignment_dict.values()))\n",
    "    for i, key in tqdm(enumerate(keys), total=B_neg_T.shape[0], desc='Computing B_neg_T...'):\n",
    "        B_neg_T[i] = entity2vec2[key] if isinstance(entity2vec2, dict) else entity2vec2.loc[key].values\n",
    "        \n",
    "    return (A_neg_S-mean_S)/scale_S, (B_neg_T-mean_T)/scale_T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "declared-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_alignment_knn(S_eval, T_eval, R, hit_values = [1, 3, 10]):\n",
    "    \"\"\"The function takes the evaluation sets, i.e. correct alignments that were left out, and returns the hits@ and MRR results w.r.t. correct alignments\n",
    "    \n",
    "    \"\"\"\n",
    "    print('#'*50)\n",
    "    print('Evaluation started...')\n",
    "    print('#'*50)\n",
    "    model = NearestNeighbors(n_neighbors=S_eval.shape[0], n_jobs=-1)\n",
    "    print('Fitting...')\n",
    "    model.fit(T_eval)\n",
    "    print('Predicting...')\n",
    "    preds = model.kneighbors((S_eval@R+T_eval)/2, n_neighbors=S_eval.shape[0], return_distance=False)\n",
    "    Hits = np.zeros(len(hit_values))\n",
    "    MRR = 0.0\n",
    "    for i in tqdm(range(S_eval.shape[0]), total=S_eval.shape[0]):\n",
    "        pred_idx = (preds[i]==i).nonzero()[0][0] # if i in preds[i] else S_eval.shape[0]\n",
    "        MRR += (1./(pred_idx+1))\n",
    "        for j in range(len(Hits)):\n",
    "            if pred_idx < hit_values[j]:\n",
    "                Hits[j] += 1.0/S_eval.shape[0]\n",
    "    MRR = MRR/S_eval.shape[0]\n",
    "    print()\n",
    "    print(', '.join([f'Hits@{hit_values[it]}: {Hits[it]}' for it in range(len(Hits))]+[f'MRR: {MRR}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "female-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnFr_shallom_embs_v1 = pd.read_csv('Shallom_EnFr_15K_V1/Shallom_entity_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "widespread-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr_shallom_embs_v1 = EnFr_shallom_embs_v1[EnFr_shallom_embs_v1['Unnamed: 0'].apply(lambda x: 'fr.dbpedia.org' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cleared-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "En_shallom_embs_v1 = EnFr_shallom_embs_v1.iloc[np.setdiff1d(np.arange(EnFr_shallom_embs_v1.shape[0]),\\\n",
    "                                                            np.array(Fr_shallom_embs_v1.index))].set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spanish-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr_shallom_embs_v1 = Fr_shallom_embs_v1.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "western-singer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://dbpedia.org/resource/Jean_Raoux_(soldier)</th>\n",
       "      <td>0.212930</td>\n",
       "      <td>-0.456497</td>\n",
       "      <td>-0.804834</td>\n",
       "      <td>-0.044535</td>\n",
       "      <td>0.363582</td>\n",
       "      <td>-0.178872</td>\n",
       "      <td>0.385574</td>\n",
       "      <td>-0.230661</td>\n",
       "      <td>0.052410</td>\n",
       "      <td>-0.681095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315135</td>\n",
       "      <td>0.187490</td>\n",
       "      <td>0.047470</td>\n",
       "      <td>0.199877</td>\n",
       "      <td>-0.045452</td>\n",
       "      <td>-0.219743</td>\n",
       "      <td>0.397735</td>\n",
       "      <td>-0.400206</td>\n",
       "      <td>-0.561423</td>\n",
       "      <td>-0.075315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://dbpedia.org/resource/Casually_Dressed_&amp;_Deep_in_Conversation</th>\n",
       "      <td>-0.040372</td>\n",
       "      <td>0.139974</td>\n",
       "      <td>0.110328</td>\n",
       "      <td>-0.021151</td>\n",
       "      <td>0.499682</td>\n",
       "      <td>-0.227622</td>\n",
       "      <td>-0.223775</td>\n",
       "      <td>0.232769</td>\n",
       "      <td>0.114076</td>\n",
       "      <td>0.240751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085454</td>\n",
       "      <td>-0.053321</td>\n",
       "      <td>0.221335</td>\n",
       "      <td>-0.010698</td>\n",
       "      <td>0.285245</td>\n",
       "      <td>-0.098031</td>\n",
       "      <td>-0.010921</td>\n",
       "      <td>-0.012190</td>\n",
       "      <td>-0.076274</td>\n",
       "      <td>0.084391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://dbpedia.org/resource/Resolve_(song)</th>\n",
       "      <td>0.093407</td>\n",
       "      <td>0.785593</td>\n",
       "      <td>0.767466</td>\n",
       "      <td>0.389821</td>\n",
       "      <td>0.748004</td>\n",
       "      <td>-0.499349</td>\n",
       "      <td>0.325547</td>\n",
       "      <td>0.308278</td>\n",
       "      <td>0.554449</td>\n",
       "      <td>0.535334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245889</td>\n",
       "      <td>0.659989</td>\n",
       "      <td>0.651668</td>\n",
       "      <td>-0.110942</td>\n",
       "      <td>0.624555</td>\n",
       "      <td>-0.312246</td>\n",
       "      <td>0.011697</td>\n",
       "      <td>-0.722449</td>\n",
       "      <td>-0.116795</td>\n",
       "      <td>0.297614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           0         1  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Jean_Raoux_(soldier)    0.212930 -0.456497   \n",
       "http://dbpedia.org/resource/Casually_Dressed_&_... -0.040372  0.139974   \n",
       "http://dbpedia.org/resource/Resolve_(song)          0.093407  0.785593   \n",
       "\n",
       "                                                           2         3  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Jean_Raoux_(soldier)   -0.804834 -0.044535   \n",
       "http://dbpedia.org/resource/Casually_Dressed_&_...  0.110328 -0.021151   \n",
       "http://dbpedia.org/resource/Resolve_(song)          0.767466  0.389821   \n",
       "\n",
       "                                                           4         5  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Jean_Raoux_(soldier)    0.363582 -0.178872   \n",
       "http://dbpedia.org/resource/Casually_Dressed_&_...  0.499682 -0.227622   \n",
       "http://dbpedia.org/resource/Resolve_(song)          0.748004 -0.499349   \n",
       "\n",
       "                                                           6         7  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Jean_Raoux_(soldier)    0.385574 -0.230661   \n",
       "http://dbpedia.org/resource/Casually_Dressed_&_... -0.223775  0.232769   \n",
       "http://dbpedia.org/resource/Resolve_(song)          0.325547  0.308278   \n",
       "\n",
       "                                                           8         9  ...  \\\n",
       "Unnamed: 0                                                              ...   \n",
       "http://dbpedia.org/resource/Jean_Raoux_(soldier)    0.052410 -0.681095  ...   \n",
       "http://dbpedia.org/resource/Casually_Dressed_&_...  0.114076  0.240751  ...   \n",
       "http://dbpedia.org/resource/Resolve_(song)          0.554449  0.535334  ...   \n",
       "\n",
       "                                                         290       291  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Jean_Raoux_(soldier)    0.315135  0.187490   \n",
       "http://dbpedia.org/resource/Casually_Dressed_&_...  0.085454 -0.053321   \n",
       "http://dbpedia.org/resource/Resolve_(song)          0.245889  0.659989   \n",
       "\n",
       "                                                         292       293  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Jean_Raoux_(soldier)    0.047470  0.199877   \n",
       "http://dbpedia.org/resource/Casually_Dressed_&_...  0.221335 -0.010698   \n",
       "http://dbpedia.org/resource/Resolve_(song)          0.651668 -0.110942   \n",
       "\n",
       "                                                         294       295  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Jean_Raoux_(soldier)   -0.045452 -0.219743   \n",
       "http://dbpedia.org/resource/Casually_Dressed_&_...  0.285245 -0.098031   \n",
       "http://dbpedia.org/resource/Resolve_(song)          0.624555 -0.312246   \n",
       "\n",
       "                                                         296       297  \\\n",
       "Unnamed: 0                                                               \n",
       "http://dbpedia.org/resource/Jean_Raoux_(soldier)    0.397735 -0.400206   \n",
       "http://dbpedia.org/resource/Casually_Dressed_&_... -0.010921 -0.012190   \n",
       "http://dbpedia.org/resource/Resolve_(song)          0.011697 -0.722449   \n",
       "\n",
       "                                                         298       299  \n",
       "Unnamed: 0                                                              \n",
       "http://dbpedia.org/resource/Jean_Raoux_(soldier)   -0.561423 -0.075315  \n",
       "http://dbpedia.org/resource/Casually_Dressed_&_... -0.076274  0.084391  \n",
       "http://dbpedia.org/resource/Resolve_(song)         -0.116795  0.297614  \n",
       "\n",
       "[3 rows x 300 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "En_shallom_embs_v1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "indie-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OpenEA_dataset_v1.1/EN_FR_15K_V1/ent_links') as file:\n",
    "    en_to_fr_ents_v1 = file.read().strip().split('\\n')\n",
    "en_to_fr_ents_v1 = dict([line.split('\\t') for line in en_to_fr_ents_v1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "consolidated-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OpenEA_dataset_v1.1/EN_FR_15K_V1/721_5fold/1/test_links') as file:\n",
    "    test_set = file.read().strip().split('\\n')\n",
    "test_set = [line.split('\\t')[0] for line in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ranging-front",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "progressive-driver",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 4500/4500 [00:00<00:00, 5095.39it/s]\n",
      "Computing S_eval and T_eval: 100%|██████████| 10500/10500 [00:02<00:00, 5103.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  7.206529678496194\n",
      "\n",
      "Completed after 0.146575927734375 seconds\n",
      "Alignment loss:  1746.1492506830389\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _, _, _, S_eval, T_eval, R = get_source_and_target_matrices(en_to_fr_ents_v1,\\\n",
    "                                                En_shallom_embs_v1, Fr_shallom_embs_v1, given_test_set=test_set, emb_dim=300, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "compatible-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting...\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10500/10500 [00:00<00:00, 44094.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hits@1: 0.7917142857144354, Hits@3: 0.8587619047620917, Hits@5: 0.8838095238097247, Hits@10: 0.9107619047621206, MRR: 0.8333291456075708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_alignment_knn(S_eval, T_eval, R, hit_values=[1, 3, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "taken-situation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 15000/15000 [00:02<00:00, 5174.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  7.246380617560009\n",
      "\n",
      "Completed after 0.1604175567626953 seconds\n",
      "Alignment loss:  5129.786850424131\n"
     ]
    }
   ],
   "source": [
    "scale_S, scale_T, mean_S, mean_T, S, T, R = get_source_and_target_matrices(en_to_fr_ents_v1,\\\n",
    "                                                                                    En_shallom_embs_v1, Fr_shallom_embs_v1, emb_dim=300, test_size=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tamil-gamma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting...\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:00<00:00, 34964.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hits@1: 0.8333999999999278, Hits@3: 0.8867999999999219, Hits@5: 0.9061999999999197, Hits@10: 0.928066666666584, MRR: 0.8668758944345571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_alignment_knn(S, T, R, hit_values=[1, 3, 5, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-queue",
   "metadata": {},
   "source": [
    "### Get non aligned entity embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "animal-asbestos",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing A_neg_S...: 0it [00:00, ?it/s]\n",
      "Computing B_neg_T...: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "A_neg_S, B_neg_T = get_non_aligned_entity_embedding_matrices(en_to_fr_ents_v1, En_shallom_embs_v1, \\\n",
    "                                                             Fr_shallom_embs_v1, scale_S, scale_T, mean_S, mean_T, emb_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "major-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute every s_i as (s_i@R+t_i)/2\n",
    "S = (S@R + T)/2\n",
    "del T\n",
    "gc.collect()\n",
    "Universal_Emb = np.concatenate([A_neg_S@R, B_neg_T, S], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "promotional-artist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Universal_Emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "light-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Shallom_EnFr_15K_V1/Universal_Emb.npy', Universal_Emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "interpreted-bunny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  15000\n"
     ]
    }
   ],
   "source": [
    "list_merged_entities = sorted(set(En_shallom_embs_v1.index)-set(en_to_fr_ents_v1.keys())) +\\\n",
    "sorted(set(Fr_shallom_embs_v1.index)-set(en_to_fr_ents_v1.values())) + \\\n",
    "list(en_to_fr_ents_v1.keys())\n",
    "print('Total: ', len(list_merged_entities))\n",
    "with open('Shallom_EnFr_15K_V1/list_merged_entities_db_fr_en.txt', 'w') as file:\n",
    "    file.write(','.join(list_merged_entities))\n",
    "del list_merged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "labeled-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Shallom_EnFr_15K_V1/english2french.txt', 'w') as file:\n",
    "    json.dump(en_to_fr_ents_v1, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dominican-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Shallom_EnFr_15K_V1/french2english.txt', 'w') as file:\n",
    "    json.dump({value:key for key,value in en_to_fr_ents_v1.items()}, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-brooks",
   "metadata": {},
   "source": [
    "## Fr-En Dbpedia 100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "smooth-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnFr_shallom_embs_v1 = pd.read_csv('Shallom_EnFr_100K_V1/Shallom_entity_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "respected-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr_shallom_embs_v1 = EnFr_shallom_embs_v1[EnFr_shallom_embs_v1['Unnamed: 0'].apply(lambda x: 'fr.dbpedia.org' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "julian-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "En_shallom_embs_v1 = EnFr_shallom_embs_v1.iloc[np.setdiff1d(np.arange(EnFr_shallom_embs_v1.shape[0]),\\\n",
    "                                                            np.array(Fr_shallom_embs_v1.index))].set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lightweight-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr_shallom_embs_v1 = Fr_shallom_embs_v1.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "finnish-hostel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://dbpedia.org/resource/Early_Edition</th>\n",
       "      <td>-0.042220</td>\n",
       "      <td>-0.058320</td>\n",
       "      <td>-0.049045</td>\n",
       "      <td>0.066309</td>\n",
       "      <td>0.066571</td>\n",
       "      <td>-0.092764</td>\n",
       "      <td>-0.059072</td>\n",
       "      <td>0.050914</td>\n",
       "      <td>-0.081084</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055581</td>\n",
       "      <td>0.055496</td>\n",
       "      <td>-0.055208</td>\n",
       "      <td>-0.073004</td>\n",
       "      <td>-0.013545</td>\n",
       "      <td>0.048070</td>\n",
       "      <td>-0.022145</td>\n",
       "      <td>-0.052797</td>\n",
       "      <td>-0.065483</td>\n",
       "      <td>-0.066909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://dbpedia.org/resource/Above_the_Law_(group)</th>\n",
       "      <td>-0.046235</td>\n",
       "      <td>-0.123812</td>\n",
       "      <td>0.069596</td>\n",
       "      <td>0.065059</td>\n",
       "      <td>-0.047143</td>\n",
       "      <td>-0.042722</td>\n",
       "      <td>0.072884</td>\n",
       "      <td>0.062155</td>\n",
       "      <td>0.034932</td>\n",
       "      <td>0.113771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136137</td>\n",
       "      <td>-0.150952</td>\n",
       "      <td>-0.066169</td>\n",
       "      <td>0.040957</td>\n",
       "      <td>0.165238</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>0.054035</td>\n",
       "      <td>0.077120</td>\n",
       "      <td>0.077142</td>\n",
       "      <td>0.072234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://dbpedia.org/resource/Belmont-Broye</th>\n",
       "      <td>0.101312</td>\n",
       "      <td>0.129636</td>\n",
       "      <td>0.071503</td>\n",
       "      <td>-0.042299</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.037403</td>\n",
       "      <td>0.302014</td>\n",
       "      <td>-0.131812</td>\n",
       "      <td>-0.002979</td>\n",
       "      <td>0.089553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069410</td>\n",
       "      <td>0.276707</td>\n",
       "      <td>-0.216835</td>\n",
       "      <td>0.039518</td>\n",
       "      <td>-0.253700</td>\n",
       "      <td>0.036126</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>0.118371</td>\n",
       "      <td>0.281929</td>\n",
       "      <td>0.098770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          0         1  \\\n",
       "Unnamed: 0                                                              \n",
       "http://dbpedia.org/resource/Early_Edition         -0.042220 -0.058320   \n",
       "http://dbpedia.org/resource/Above_the_Law_(group) -0.046235 -0.123812   \n",
       "http://dbpedia.org/resource/Belmont-Broye          0.101312  0.129636   \n",
       "\n",
       "                                                          2         3  \\\n",
       "Unnamed: 0                                                              \n",
       "http://dbpedia.org/resource/Early_Edition         -0.049045  0.066309   \n",
       "http://dbpedia.org/resource/Above_the_Law_(group)  0.069596  0.065059   \n",
       "http://dbpedia.org/resource/Belmont-Broye          0.071503 -0.042299   \n",
       "\n",
       "                                                          4         5  \\\n",
       "Unnamed: 0                                                              \n",
       "http://dbpedia.org/resource/Early_Edition          0.066571 -0.092764   \n",
       "http://dbpedia.org/resource/Above_the_Law_(group) -0.047143 -0.042722   \n",
       "http://dbpedia.org/resource/Belmont-Broye          0.238900  0.037403   \n",
       "\n",
       "                                                          6         7  \\\n",
       "Unnamed: 0                                                              \n",
       "http://dbpedia.org/resource/Early_Edition         -0.059072  0.050914   \n",
       "http://dbpedia.org/resource/Above_the_Law_(group)  0.072884  0.062155   \n",
       "http://dbpedia.org/resource/Belmont-Broye          0.302014 -0.131812   \n",
       "\n",
       "                                                          8         9  ...  \\\n",
       "Unnamed: 0                                                             ...   \n",
       "http://dbpedia.org/resource/Early_Edition         -0.081084 -0.063700  ...   \n",
       "http://dbpedia.org/resource/Above_the_Law_(group)  0.034932  0.113771  ...   \n",
       "http://dbpedia.org/resource/Belmont-Broye         -0.002979  0.089553  ...   \n",
       "\n",
       "                                                         15        16  \\\n",
       "Unnamed: 0                                                              \n",
       "http://dbpedia.org/resource/Early_Edition         -0.055581  0.055496   \n",
       "http://dbpedia.org/resource/Above_the_Law_(group)  0.136137 -0.150952   \n",
       "http://dbpedia.org/resource/Belmont-Broye         -0.069410  0.276707   \n",
       "\n",
       "                                                         17        18  \\\n",
       "Unnamed: 0                                                              \n",
       "http://dbpedia.org/resource/Early_Edition         -0.055208 -0.073004   \n",
       "http://dbpedia.org/resource/Above_the_Law_(group) -0.066169  0.040957   \n",
       "http://dbpedia.org/resource/Belmont-Broye         -0.216835  0.039518   \n",
       "\n",
       "                                                         19        20  \\\n",
       "Unnamed: 0                                                              \n",
       "http://dbpedia.org/resource/Early_Edition         -0.013545  0.048070   \n",
       "http://dbpedia.org/resource/Above_the_Law_(group)  0.165238  0.015526   \n",
       "http://dbpedia.org/resource/Belmont-Broye         -0.253700  0.036126   \n",
       "\n",
       "                                                         21        22  \\\n",
       "Unnamed: 0                                                              \n",
       "http://dbpedia.org/resource/Early_Edition         -0.022145 -0.052797   \n",
       "http://dbpedia.org/resource/Above_the_Law_(group)  0.054035  0.077120   \n",
       "http://dbpedia.org/resource/Belmont-Broye          0.033697  0.118371   \n",
       "\n",
       "                                                         23        24  \n",
       "Unnamed: 0                                                             \n",
       "http://dbpedia.org/resource/Early_Edition         -0.065483 -0.066909  \n",
       "http://dbpedia.org/resource/Above_the_Law_(group)  0.077142  0.072234  \n",
       "http://dbpedia.org/resource/Belmont-Broye          0.281929  0.098770  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "En_shallom_embs_v1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "documented-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OpenEA_dataset_v1.1/EN_FR_100K_V1/ent_links') as file:\n",
    "    en_to_fr_ents_v1 = file.read().strip().split('\\n')\n",
    "en_to_fr_ents_v1 = dict([line.split('\\t') for line in en_to_fr_ents_v1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "apparent-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OpenEA_dataset_v1.1/EN_FR_100K_V1/721_5fold/1/test_links') as file:\n",
    "    test_set = file.read().strip().split('\\n')\n",
    "test_set = [line.split('\\t')[0] for line in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "english-given",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 30000/30000 [00:06<00:00, 4926.36it/s]\n",
      "Computing S_eval and T_eval: 100%|██████████| 70000/70000 [00:14<00:00, 4895.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "Scale S:  0.6159915591570903\n",
      "\n",
      "Completed after 0.01683950424194336 seconds\n",
      "Alignment loss:  6808.175185166385\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _, _, _, S_eval, T_eval, R = get_source_and_target_matrices(en_to_fr_ents_v1,\\\n",
    "                                                En_shallom_embs_v1, Fr_shallom_embs_v1, given_test_set=test_set, emb_dim=25, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "outer-daughter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting...\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70000/70000 [00:08<00:00, 8300.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hits@1: 0.11948571428572816, Hits@3: 0.19792857142859843, Hits@5: 0.23975714285717686, Hits@10: 0.30319999999994124, MRR: 0.18192219256295464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_alignment_knn(S_eval, T_eval, R, hit_values=[1, 3, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_S, scale_T, mean_S, mean_T, S, T, R = get_source_and_target_matrices(en_to_fr_ents_v1,\\\n",
    "                                                                                    En_shallom_embs_v1, Fr_shallom_embs_v1, emb_dim=300, test_size=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_alignment_knn(S, T, R, hit_values=[1, 3, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_neg_S, B_neg_T = get_non_aligned_entity_embedding_matrices(en_to_fr_ents_v1, En_shallom_embs_v1, \\\n",
    "                                                             Fr_shallom_embs_v1, scale_S, scale_T, mean_S, mean_T, emb_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute every s_i as (s_i@R+t_i)/2\n",
    "S = (S@R + T)/2\n",
    "del T\n",
    "gc.collect()\n",
    "Universal_Emb = np.concatenate([A_neg_S@R, B_neg_T, S], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "Universal_Emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Shallom_EnFr_100K_V1/Universal_Emb.npy', Universal_Emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Shallom_EnFr_100K_V1/english2french.txt', 'w') as file:\n",
    "    json.dump(en_to_fr_ents_v1, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Shallom_EnFr_100K_V1/french2english.txt', 'w') as file:\n",
    "    json.dump({value:key for key,value in en_to_fr_ents_v1.items()}, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-mobile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-therapist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unikge",
   "language": "python",
   "name": "unikge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
