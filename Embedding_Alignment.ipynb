{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "increasing-quality",
   "metadata": {},
   "source": [
    "# Reading files and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demanding-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "base_path = !pwd\n",
    "base_path = base_path[0]\n",
    "list_files = [base_path+\"/data/caligraph/\"+f for f in os.listdir(base_path+\"/data/caligraph/\") if os.path.isfile(base_path+\"/data/caligraph/\"+f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incredible-treatment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-provenance.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-transitive-types.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-to-dbpedia-mappings.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-labels.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-ontology.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-relations.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-types.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-class-to-dbpedia.nt',\n",
       " '/home/nkouagou/Documents/Universal_Embeddings/data/caligraph/caligraph-instance-provenance.nt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "medical-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(list_files[2]) as file:\n",
    "    caligraph2dbpedia_mappings = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "upper-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(mapping):\n",
    "    x,_,y,_ = mapping.split()\n",
    "    return x.strip('<>'), y.strip('<>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caroline-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "caligraph2dbpedia_mappings = dict(map(lambda x: get_map(x), caligraph2dbpedia_mappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sufficient-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://caligraph.org/resource/Cameroon_sheep',\n",
       " 'http://dbpedia.org/resource/Cameroon_sheep')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(caligraph2dbpedia_mappings.items())[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "written-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbpedia2caligraph_mappings = {value: key for key,value in caligraph2dbpedia_mappings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "measured-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facial-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_caligraph = KeyedVectors.load(\"./Caligraph_Dbpedia/caligraph/caligraph-v211_500_4_sg_200_vectors.kv\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "located-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_dbpedia = KeyedVectors.load(\"./Caligraph_Dbpedia/dbpedia/dbpedia.kv\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-track",
   "metadata": {},
   "source": [
    "### There are mismatches between entity IRIs in 'caligraph2dbpedia_mappings' and those in the computed embeddings, see below. We will write a function that fixes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "judicial-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_namespace(iri, kg='dbpedia'):\n",
    "    if kg == 'dbpedia':\n",
    "        if 'owl#' in iri:\n",
    "            return iri\n",
    "        iri = iri.replace('dbr:', 'http://dbpedia.org/resource/')\n",
    "        return 'http://dbpedia.org/resource/' + iri.split('/')[-1]\n",
    "    elif kg == 'caligraph':\n",
    "        if 'owl#' in iri or 'ontology' in iri:\n",
    "            return iri\n",
    "        return 'http://caligraph.org/resource/' + iri.split('/')[-1]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "located-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emb_keys_db = set(map(lambda t: repair_namespace(t), word_vectors_dbpedia.key_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "conventional-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emb_keys_cal = set(map(lambda t: repair_namespace(t, 'caligraph'), word_vectors_caligraph.key_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "documented-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-deficit",
   "metadata": {},
   "source": [
    "### Creating entity to vector maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "technical-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2vec_db = {}\n",
    "entity2vec_cal = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "attended-characteristic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15048578/15048578 [02:18<00:00, 108524.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for ent in tqdm(word_vectors_dbpedia.key_to_index):\n",
    "    try:\n",
    "        entity2vec_db[repair_namespace(ent)] = np.array(word_vectors_dbpedia.get_vector(ent))\n",
    "    except KeyError:\n",
    "        if repair_namespace(ent) in entity2vec_db:\n",
    "            entity2vec_db.pop(repair_namespace(ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "romance-vacation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16429696/16429696 [02:19<00:00, 117376.20it/s]\n"
     ]
    }
   ],
   "source": [
    "for ent in tqdm(word_vectors_caligraph.key_to_index):\n",
    "    try:\n",
    "        entity2vec_cal[repair_namespace(ent, 'caligraph')] = np.array(word_vectors_caligraph.get_vector(ent), )\n",
    "    except KeyError:\n",
    "        if repair_namespace(ent) in entity2vec_cal:\n",
    "            entity2vec_cal.pop(repair_namespace(ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "proper-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_vectors_dbpedia, word_vectors_caligraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "classified-garage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8320865/8320865 [00:20<00:00, 402377.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  3745232  aligned entities with available embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_aligned_entity_dict = dict()\n",
    "\n",
    "for key, value in tqdm(caligraph2dbpedia_mappings.items()):\n",
    "    if key in entity2vec_cal and value in entity2vec_db:\n",
    "        new_aligned_entity_dict.update({key: value})\n",
    "print('There are ', len(new_aligned_entity_dict), ' aligned entities with available embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Caligraph_Dbpedia/caligraph2dbpediaalignment.json', 'w') as file:\n",
    "#    json.dump(new_aligned_entity_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-stocks",
   "metadata": {},
   "source": [
    "# Computing aligned KG embeddings using Orthogonal Procrustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "atomic-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import procrustes\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import time, gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-marketplace",
   "metadata": {},
   "source": [
    "## Get the embedding matrices of aligned entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "active-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_and_target_matrices(alignment_dict, entity2vec1, entity2vec2, test_size=0.1):\n",
    "    \"\"\"This function takes the dictionary of aligned entities between two KGs and their corresponding embeddings (as entity to vector dictionaries)\n",
    "    and returns S, T, S_eval, T_eval, and R defined as follows:\n",
    "    \n",
    "    -- S: Normalized large subset of the source embeddings, i.e. the matrix of aligned entity embeddings in the first knowledge graph\n",
    "    \n",
    "    -- T: Normalized large subset of the matrix of aligned entity embeddings in the second knowledge graph\n",
    "    \n",
    "    -- S_eval and T_eval are portions of S and T sampled for evaluation if test_size > 0\n",
    "    \n",
    "    -- R: The rotation matrix that most closely maps S to T, i.e. ||A@S-T|| is minimized\n",
    "    \"\"\"\n",
    "    if test_size > 0:\n",
    "        train_ents, eval_ents = train_test_split(list(alignment_dict.keys()), test_size=test_size)\n",
    "    else:\n",
    "        train_ents = alignment_dict.keys()\n",
    "    \n",
    "    S = np.empty((len(train_ents), 200), )\n",
    "    T = np.empty((len(train_ents), 200), )\n",
    "    if test_size > 0:\n",
    "        S_eval = np.empty((len(eval_ents), 200), )\n",
    "        T_eval = np.empty((len(eval_ents), 200), )\n",
    "\n",
    "    for i, key in tqdm(enumerate(train_ents), total=len(train_ents), desc='Computing S and T'):\n",
    "        S[i] = entity2vec_cal[key]\n",
    "        T[i] = entity2vec_db[new_aligned_entity_dict[key]]\n",
    "        \n",
    "    if test_size > 0:\n",
    "        for i, key in tqdm(enumerate(eval_ents), total=len(eval_ents), desc='Computing S_eval and T_eval'):\n",
    "            S_eval[i] = entity2vec_cal[key]\n",
    "            T_eval[i] = entity2vec_db[new_aligned_entity_dict[key]]\n",
    "        \n",
    "    print('\\nNow computing R...')\n",
    "    \n",
    "    t0 = time.time()\n",
    "    R, scale = orthogonal_procrustes(S/np.sqrt((S**2).sum()), T/np.sqrt((T**2).sum()), check_finite=True)\n",
    "    print('\\nCompleted after '+str(time.time()-t0)+' seconds')\n",
    "    print('scale: ', scale)\n",
    "    \n",
    "    if test_size > 0:\n",
    "        return S/np.sqrt((S**2).sum()), T/np.sqrt((T**2).sum()), S_eval/np.sqrt((S_eval**2).sum()), T_eval/np.sqrt((T_eval**2).sum()), R\n",
    "    else:\n",
    "        return S/np.sqrt((S**2).sum()), T/np.sqrt((T**2).sum()), R\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "martial-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_aligned_entity_embedding_matrices(alignment_dict, entity2vec1, entity2vec2):\n",
    "    \"\"\"\n",
    "    Inputs the dictionary of aligned entities between two KGs and their corresponding embeddings, and returns the normalized embedding matrices of \n",
    "    \n",
    "    non-aligned entities\n",
    "    \"\"\"\n",
    "    A_neg_S = np.empty((len(entity2vec1)-len(alignment_dict), 200))\n",
    "    keys = sorted(set(entity2vec1.keys())-set(alignment_dict.keys()))\n",
    "    for i, key in tqdm(enumerate(keys), total=A_neg_S.shape[0], desc='Computing A_neg_S...'):\n",
    "        A_neg_S[i] = entity2vec1[key]\n",
    "    \n",
    "    B_neg_T = np.empty((len(entity2vec2)-len(alignment_dict), 200))\n",
    "    keys = sorted(set(entity2vec2.keys())-set(alignment_dict.values()))\n",
    "    for i, key in tqdm(enumerate(keys), total=B_neg_T.shape[0], desc='Computing B_neg_T...'):\n",
    "        B_neg_T[i] = entity2vec2[key]\n",
    "    \n",
    "    return A_neg_S/np.sqrt((A_neg_S**2).sum()), B_neg_T/np.sqrt((B_neg_T**2).sum())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-enough",
   "metadata": {},
   "source": [
    "## Evaluating Procrustes alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ruled-albania",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 3370708/3370708 [00:28<00:00, 118221.79it/s]\n",
      "Computing S_eval and T_eval: 100%|██████████| 374524/374524 [00:02<00:00, 136812.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "\n",
      "Completed after 18.258718013763428 seconds\n",
      "scale:  0.43751756553668897\n"
     ]
    }
   ],
   "source": [
    "S, T, S_eval, T_eval, R = get_source_and_target_matrices(new_aligned_entity_dict, entity2vec_cal, entity2vec_db, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "polar-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "naked-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_alignment_knn(S_eval, T_eval, R):\n",
    "    \"\"\"The function takes the evaluation sets, i.e. correct alignments that were left out, and returns the accuracy computed as the proportion\n",
    "    of correct alignment predictions\n",
    "    \n",
    "    \"\"\"\n",
    "    print('#'*50)\n",
    "    print('Evaluation started...')\n",
    "    print('#'*50)\n",
    "    model = NearestNeighbors(n_neighbors=1, n_jobs=-1)\n",
    "    print('Fitting...')\n",
    "    model.fit(S_eval@R)\n",
    "    print('Predicting...')\n",
    "    preds = model.kneighbors(T_eval, 1, return_distance=False)\n",
    "    preds = preds.reshape(-1,)\n",
    "    acc = (np.array(preds) == np.arange(S_eval.shape[0])).astype(float).sum()\n",
    "    #for i in tqdm(range(S_eval.shape[0])):\n",
    "    #    row = S_eval[i][None, :]\n",
    "    #    acc += ((T_eval - (row@R).squeeze())**2).sum(axis=1).argmin() == i\n",
    "    #    #if i > 0 and i%100 == 0:\n",
    "    #    #    print('acc:', acc/i)\n",
    "    return acc / S_eval.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "electoral-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_alignment(S_eval, T_eval, R, num_candidates=10):\n",
    "    \"\"\"The function takes the evaluation sets, i.e. correct alignments that were left out, and returns the accuracy computed as the proportion\n",
    "    of correct alignment predictions\n",
    "    \n",
    "    \"\"\"\n",
    "    print('#'*50)\n",
    "    print('Evaluation started...')\n",
    "    print('#'*50)\n",
    "    acc = 0\n",
    "    ids = list(range(S_eval.shape[0]))\n",
    "    for i in tqdm(range(S_eval.shape[0])):\n",
    "        s_i = S_eval[i][None, :]@R\n",
    "        rand_ids = list(set(random.sample(ids, k=num_candidates))-{i})\n",
    "        candidates = np.concatenate([T_eval[i][None, :], T_eval[rand_ids[:num_candidates-1]]], axis=0)\n",
    "        acc += ((candidates-s_i)**2).sum(1).squeeze().argmin() == 1\n",
    "    return acc / S_eval.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "crazy-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 374524/374524 [05:20<00:00, 1168.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data:  0.08155685616943106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_alignment(S_eval.astype(np.float16), T_eval.astype(np.float16), R.astype(np.float16))\n",
    "print('Accuracy on validation data: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "union-centre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Evaluation started...\n",
      "##################################################\n",
      "Fitting...\n",
      "Predicting...\n",
      "Accuracy on validation data:  0.0003497773173414788\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_alignment_knn(S_eval.astype(np.float16), T_eval.astype(np.float16), R.astype(np.float16))\n",
    "print('Accuracy on validation data: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-browse",
   "metadata": {},
   "source": [
    "## Computing and storing universal embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del S, T, S_eval, T_eval, R\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "magnetic-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_merged_entities = sorted(set(entity2vec_cal.keys())-set(new_aligned_entity_dict.keys())) +\\\n",
    "sorted(set(entity2vec_db.keys())-set(new_aligned_entity_dict.values())) + \\\n",
    "list(new_aligned_entity_dict.keys())\n",
    "with open('Caligraph_Dbpedia/list_merged_entities_cal_db.txt', 'w') as file:\n",
    "    file.write(','.join(list_merged_entities))\n",
    "del list_merged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "mobile-catholic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sorted-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing S and T: 100%|██████████| 3745232/3745232 [00:29<00:00, 128254.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now computing R...\n",
      "\n",
      "Completed after 16.62036395072937 seconds\n",
      "scale:  0.437522492358588\n"
     ]
    }
   ],
   "source": [
    "S, T, R = get_source_and_target_matrices(new_aligned_entity_dict, entity2vec_cal, entity2vec_db, test_size=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "identical-discovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing A_neg_S...: 100%|██████████| 12670001/12670001 [00:37<00:00, 341252.82it/s]\n",
      "Computing B_neg_T...: 100%|██████████| 6280733/6280733 [00:21<00:00, 291409.57it/s]\n"
     ]
    }
   ],
   "source": [
    "A_neg_S, B_neg_T = get_non_aligned_entity_embedding_matrices(new_aligned_entity_dict, entity2vec_cal, entity2vec_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "coastal-digit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del entity2vec_cal, entity2vec_db\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "featured-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute every s_i as (s_i@R+t_i)/2\n",
    "S = (S@R + T)/2\n",
    "del T\n",
    "gc.collect()\n",
    "Universal_Emb = np.concatenate([A_neg_S@R, B_neg_T, S], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adjustable-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Caligraph_Dbpedia/Universal_Emb.npy', Universal_Emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "medical-technique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22695966, 200)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Universal_Emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-guyana",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unikge",
   "language": "python",
   "name": "unikge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
