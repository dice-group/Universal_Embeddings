{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9820d8-0806-484a-a72b-7448c606b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#covert data from parquet\n",
    "from fastparquet import ParquetFile\n",
    "filename = \"dbpedia_09_2022.parquet\"\n",
    "pf = ParquetFile(filename)\n",
    "df = pf.to_pandas()\n",
    "df.to_csv(\"dbpedia_09_2022.txt\",sep='\\t',index=False)\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0dd0a2-eb63-4e6c-a6d1-bb7c4144e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write DB file with correctly format\n",
    "\n",
    "file_rel_DB ='dbpedia_09_2022.txt'\n",
    "file_rel_write_sameas='sameas.txt'\n",
    "file_rel_DB_without_sameas_error ='dbpedia_09_2022_version_merge.txt'\n",
    "file_rel_DB_without_error ='dbpedia_09_2022_version.txt'\n",
    "\n",
    "filerel_write_sameas = open(file_rel_write_sameas, 'w', encoding='utf-8')\n",
    "filerel_DB_without_error = open(file_rel_DB_without_error ,'w', encoding='utf-8')\n",
    "filerel_DB_without_sameas_error = open(file_rel_DB_without_sameas_error, 'w', encoding='utf-8')\n",
    "\n",
    "def read_triple_dbp_raw(file_path):\n",
    "    num=0\n",
    "    num1=0\n",
    "    num2=0\n",
    "    outputsame=''\n",
    "    outputwithouterror=''\n",
    "    outputwithouterrorsameas=''\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            \n",
    "            line = line.strip('\\n').split()\n",
    "            if len(line) != 3:\n",
    "                continue\n",
    "            s = line[0].lstrip('<').rstrip('>')\n",
    "            p = line[1].lstrip('<').rstrip('>')\n",
    "            o = line[2].lstrip('<').rstrip('>')\n",
    "            #write in to version1\n",
    "            num=num+1\n",
    "            outputwithouterror ='<'+ s +'>'+'\\t'+'<'+ p +'>'+'\\t'+'<'+ o +'> .''\\n'\n",
    "            filerel_DB_without_error.write(outputwithouterror)\n",
    "            if 'http://www.w3.org/2002/07/owl#sameAs' in p  and 'http://www.wikidata.org/entity'  in o:\n",
    "                num1=num1+1\n",
    "                outputsame='<'+ s +'>'+'\\t'+'<'+ p +'>'+'\\t'+'<'+ o +'> .''\\n'\n",
    "                filerel_write_sameas.write(outputsame)\n",
    "            if 'http://www.w3.org/2002/07/owl#sameAs' not in p:\n",
    "                num2=num2+1\n",
    "                outputwithouterrorsameas='<'+ s +'>'+'\\t'+'<'+ p +'>'+'\\t'+'<'+ o +'> .''\\n'\n",
    "                filerel_DB_without_sameas_error.write(outputwithouterrorsameas)\n",
    "                \n",
    "        print(num)\n",
    "        print(num1)\n",
    "        print(num2)\n",
    "                \n",
    "\n",
    "            \n",
    "read_triple_dbp_raw(file_rel_DB)\n",
    "\n",
    "\n",
    "#758227396 without error\n",
    "#33860047 same \n",
    "#724367349\n",
    "#724367311\n",
    "#616564612 witout same and error\n",
    "#616564604\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300aab5-52c3-41b1-aa52-5c8d82cc02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete 1st line from dbpedia_09_2022_version.txt and dbpedia_09_2022_version_merge.txt\n",
    "#because the 1st was from dbpedia_09_2022.txtï¼Œwere the column names of the table <subjetc> <relation> <object>\n",
    "sed -i '1d' dbpedia_09_2022_version_merge.txt\n",
    "\n",
    "sed -i '1d' dbpedia_09_2022_version.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c04043-fda0-4dfb-ae67-e50e06ecb6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergeentities\n",
    "file_rel_in_WIKI= 'data.txt'\n",
    "file_rel_sameAS= 'sameas.txt'\n",
    "file_rel_in_DB= 'dbpedia_09_2022_version_merge.txt'\n",
    "filewrite = open('mergeentities.txt', 'a', encoding='utf-8')\n",
    "\n",
    "\n",
    "def read_DBandWIKI(file_path):\n",
    "    dictwiki=dict()\n",
    "  #(DB,wiki)\n",
    "    num=0\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip(' .\\n').split()\n",
    "            if len(line) != 3:\n",
    "                \n",
    "                continue\n",
    "            num=num+1\n",
    "            s = line[0].lstrip('<').rstrip('>') #db\n",
    "            p = line[1].lstrip('<').rstrip('>')\n",
    "            o = line[2].lstrip('<').rstrip('>')#wiki\n",
    "            dictwiki[s]=o\n",
    "            #dictwikibackforward[o]=s    \n",
    "            \n",
    "            \"\"\"\n",
    "            keys = dictwiki.keys()\n",
    "            if s not in keys: #(DB,wiki)\n",
    "            \"\"\"\n",
    "                #listtriplebackforward=set()\n",
    "               \n",
    "                #dictwiki[s]=o\n",
    "        return dictwiki\n",
    "\n",
    "def read_WIKIandDB(file_path):\n",
    "    #(Wiki,db)\n",
    "    dictwikibackforward=dict()\n",
    "    num=0\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip(' .\\n').split()\n",
    "            if len(line) != 3:\n",
    "                continue\n",
    "            num=num+1\n",
    "            s = line[0].lstrip('<').rstrip('>') #DB\n",
    "            p = line[1].lstrip('<').rstrip('>')\n",
    "            o = line[2].lstrip('<').rstrip('>') #wiki\n",
    "            \"\"\"\n",
    "            keysbackforward = dictwikibackforward.keys()\n",
    "            if o not in keysbackforward: #(wiki,db)\n",
    "                #listtriplebackforward=set()\n",
    "                \"\"\"\n",
    "            dictwikibackforward[o]=s    \n",
    "            \n",
    "        #(wiki,db)\n",
    "    return dictwikibackforward    \n",
    "\n",
    "#replace\n",
    "def replace_entity_in_DB(file_path,dictbackforward):\n",
    "#(wiki,db)\n",
    "    numoindata=0\n",
    "    numberout=0\n",
    "    output=''\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            numoindata=numoindata+1\n",
    "            line = line.strip(' .\\n').split()\n",
    "            if len(line) != 3:\n",
    "                continue\n",
    "            s = line[0].lstrip('<').rstrip('>')# wiki\n",
    "            p = line[1].lstrip('<').rstrip('>')\n",
    "            o = line[2].lstrip('<').rstrip('>') #wiki\n",
    "            \n",
    "                #(wiki,db)\n",
    "\n",
    "            rl=str(p).replace(\"http://www.wikidata.org/\",\"http://embedding.cc/\")\n",
    "                \n",
    "                #replacevaluehead=set()\n",
    "               \n",
    "            head=str(s).replace(\"http://www.wikidata.org/\",\"http://embedding.cc/\")\n",
    "               \n",
    "               \n",
    "                #double check if replacevalue in dicforward keys\n",
    "                \n",
    "               # print(\"the tail entity should be replaced is \"+o)\n",
    "                \n",
    "                \n",
    "            tail=str(o).replace(\"http://www.wikidata.org/\",\"http://embedding.cc/\")\n",
    "               \n",
    "            output ='<'+ head +'>'+'\\t'+'<'+ rl +'>'+'\\t'+'<'+ tail +'> .''\\n'\n",
    "            numberout=numberout+1\n",
    "               \n",
    "            filewrite.write(output)\n",
    "        print(\"the match number is\" + str(numberout))\n",
    "\n",
    "def replace_entity_into_WIKI(file_path,dictforward):\n",
    "#(DB,wiki)\n",
    "#\n",
    "    numoindata=0 \n",
    "    numberout=0\n",
    "    output=''\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip(' .\\n').split()\n",
    "            if len(line) != 3:\n",
    "                continue\n",
    "            s = line[0].lstrip('<').rstrip('>')# db\n",
    "            p = line[1].lstrip('<').rstrip('>')\n",
    "            o = line[2].lstrip('<').rstrip('>') # db\n",
    "            numoindata=numoindata+1\n",
    "            uri=p.split('/')\n",
    "            newuri=p.replace(uri[2],\"embedding.cc\")\n",
    "           \n",
    "      \n",
    "            \n",
    "            if s in dictforward.keys() or o in dictforward.keys():\n",
    "                \n",
    "                replacevaluehead=dictforward.get(s) #wik\n",
    "                if replacevaluehead is None:\n",
    "                    head=str(s).replace(\"http://dbpedia.org/\",\"http://embedding.cc/\")\n",
    "                else:\n",
    "                    head=str(replacevaluehead).replace(\"http://www.wikidata.org/\",\"http://embedding.cc/\")\n",
    "              \n",
    "                replacevaluetail=dictforward.get(o)\n",
    "                if replacevaluetail is None:\n",
    "                    tail=str(o).replace(\"http://dbpedia.org/\",\"http://embedding.cc/\")\n",
    "                else:\n",
    "\n",
    "                    tail=str(replacevaluetail).replace(\"http://www.wikidata.org/\",\"http://embedding.cc/\")\n",
    "            #if s in dictforward.keys() or o in dictforward.keys():\n",
    "            else:\n",
    "                head=str(s).replace(\"http://dbpedia.org/\",\"http://embedding.cc/\")\n",
    "                tail=str(o).replace(\"http://dbpedia.org/\",\"http://embedding.cc/\")\n",
    "            output ='<'+ head +'>'+'\\t'+'<'+ newuri +'>'+'\\t'+'<'+ tail +'> .''\\n'\n",
    "            numberout=numberout+1\n",
    "            filewrite.write(output)\n",
    "        print(\"the raw number in  DB is\" + str(numoindata))\n",
    "        print(\"the new number in  DB is\" + str(numberout))\n",
    "        \n",
    "    \n",
    "                #str(output).replace('http://dbpedia.org/','http://embedding.cc/')\n",
    "                #double check if replacevalue in dicforward key\n",
    "\n",
    "#DBreaderbackforward=read_DB_in_map2(file_rel_DB)\n",
    "DBreaderforward=read_DBandWIKI(file_rel_sameAS)\n",
    "DBreaderbackforward=read_WIKIandDB(file_rel_sameAS)\n",
    "\n",
    "#replace_entity_in_DB(file_rel_wiki,DBreaderbackforward)\n",
    "replace_entity_in_DB(file_rel_in_WIKI,DBreaderbackforward) #(wiki,db)\n",
    "replace_entity_into_WIKI(file_rel_in_DB,DBreaderforward)\n",
    "filewrite.close()\n",
    "\n",
    "#read match from theb DB sameaas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c3d13-1d90-4f52-864e-e0c5e2826991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#caculate the triples\n",
    "def readline_count(file_name):\n",
    "      with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        num=0\n",
    "        for line in file:\n",
    "           \n",
    "            line = line.strip(' .\\n').split()\n",
    "            if len(line) != 3:\n",
    "                continue\n",
    "            num=num+1\n",
    "        print(num)\n",
    "readline_count('mergeentities.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bdb9f6-4617-4e84-b85b-3d006a29d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree\n",
    "from collections import defaultdict\n",
    "def degree(file_name):\n",
    "    kg_degree = defaultdict(lambda: 0)\n",
    "    with open(file_name) as file:\n",
    "        #data = file.readlines()\n",
    "       # print(\"***Train*** Number of triples: \", len(data))\n",
    "     for triple in file:\n",
    "            triple = triple.strip(' .\\n').split()\n",
    "            e1 = triple[0].lstrip('<').rstrip('>')\n",
    "            r = triple[1].lstrip('<').rstrip('>')\n",
    "            e2 = triple[2].lstrip('<').rstrip('>')\n",
    "            kg_degree[e1] += 1\n",
    "            kg_degree[e2] += 1\n",
    "    return kg_degree\n",
    "\n",
    "import numpy as np\n",
    "degrees = degree(\"mergeentities.txt\") ## Replace by KG file name here. In our case, you will do it for 3 KGs: mergeentities.txt, DBpedia.txt, Wikidata.txt\n",
    "print(\"Avg. degree:\", np.array(list(degrees.values())).mean())\n",
    "\n",
    "#merge Avg. degree: 14.288348430923302\n",
    "\n",
    "#db Avg. degree: 10.403151794296798\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc2fde-1474-4534-bbc0-af53921aad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kg_size(file_name):\n",
    "    E = set() # entities\n",
    "    R = set() # relations\n",
    "    with open(file_name) as file:\n",
    "        #data = file.readlines()\n",
    "        for triple in file:\n",
    "            triple = triple.strip(' .\\n').split()\n",
    "           \n",
    "            e1 = triple[0].lstrip('<').rstrip('>')# db\n",
    "            r = triple[1].lstrip('<').rstrip('>')# db\n",
    "            e2 = triple[2].lstrip('<').rstrip('>')# db\n",
    "            \n",
    "            E.update({e1, e2})\n",
    "            R.add(r)\n",
    "    print(f\"#Entities: {len(E)}, #Relations: {len(R)}\")\n",
    "#kg_size('data.txt')\n",
    "kg_size('mergeentities.txt')\n",
    "##Entities: 145768777, #Relations: 13784\n",
    "#Entities: 179759154, #Relations: 15219"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
